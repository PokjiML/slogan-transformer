{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer model with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim                         # Adam optimizer\n",
    "import torch.nn.functional as F                     # Softmax function\n",
    "from torch.utils.data import DataLoader, Dataset    # Loading batches\n",
    "import torch.nn.utils.rnn as rnn_utils              # Padding the sequence\n",
    "from torch.optim.lr_scheduler import OneCycleLR     # Learning rate scheduler\n",
    "from transformers import AutoTokenizer              # BPE Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_slogans = pd.read_csv('all_slogans.csv', sep=';')\n",
    "slogans = all_slogans['slogan']\n",
    "slogans = slogans.str.lower()\n",
    "\n",
    "# reducing invaluable tokens\n",
    "to_remove = ['\\n', '\\r', '>', '\\x80', '\\x93', '\\x94', '\\x99', '\\x9d', '\\xa0',\n",
    "             '¦', '®', '°', 'º', '¼', '½','×', 'â', 'ã', 'è', 'é', 'ï', 'ñ', 'ú', 'ü',\n",
    "             '⁄', '（', '）', '，', '·']\n",
    "\n",
    "dict_to_remove = {\"’\" : \"'\", \"‘\" : \"'\", \"“\" : '\"', \"”\" : '\"',\n",
    "                  \"…\" : '...', '—': '-', '–': '-'}\n",
    "\n",
    "\n",
    "# removing useless toknes\n",
    "for char in to_remove:\n",
    "    slogans = slogans.str.replace(char, ' ')\n",
    "\n",
    "# replacing tokens with normalised versions\n",
    "for key, value in dict_to_remove.items():\n",
    "    slogans = slogans.str.replace(key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] the way i like to travel [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BPE tokenizer for bert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenizing the dataset\n",
    "encoded_slogans = tokenizer.batch_encode_plus(\n",
    "    slogans.tolist(),\n",
    "    add_special_tokens=True, # <BoS> and <EoS>\n",
    "    padding=True,            # Pad for same seq_length\n",
    "    truncation=True,         # Truncate to max length\n",
    "    return_tensors='pt'      # Torch datatype\n",
    ")\n",
    "\n",
    "# Focusing only on tokens\n",
    "encoded_slogans = encoded_slogans['input_ids']\n",
    "\n",
    "# test example\n",
    "encoded_slogans.shape\n",
    "tokenizer.decode(encoded_slogans[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11646, 35])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_slogans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "vocab_size = tokenizer.vocab_size\n",
    "d_model = 512 # dim of the embedding vector               # From 384\n",
    "nhead = 8 # number of attention heads                     # From 8\n",
    "num_decoder_layers = 8 # number of decoder layers         # From 3\n",
    "dim_feedforward = 4096 # feed-forward network dimension   # From 2048\n",
    "max_seq_length = 20                                       # From 20\n",
    "batch_size = 128                                          # From 128\n",
    "dropout = 0.2                                             # From 0.1            \n",
    "PAD_TOKEN = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SloganDataset(Dataset):\n",
    "    def __init__(self, encoded_slogans, max_seq_length=20):\n",
    "        self.encoded_slogans = encoded_slogans \n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_slogans)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        slogan = self.encoded_slogans[idx]\n",
    "        \n",
    "        # Truncate if slogan is too long\n",
    "        if len(slogan) > self.max_seq_length:\n",
    "            slogan = slogan[:self.max_seq_length]     \n",
    "\n",
    "        input_sequence = slogan[:-1]\n",
    "        target_sequence = slogan[1:]\n",
    "        return input_sequence, target_sequence\n",
    "    \n",
    "\n",
    "\n",
    "# Test with subset of slogans\n",
    "subset_encoded_slogans = encoded_slogans\n",
    "dataset = SloganDataset(subset_encoded_slogans)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Positional Encoding and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinusoidal positional encoding\n",
    "def positional_encoding(seq_len, embed_dim):\n",
    "    pe = torch.zeros(seq_len, embed_dim)\n",
    "    for pos in range(seq_len):\n",
    "        for i in range(0, embed_dim, 2):\n",
    "            pe[pos, i] = math.sin(pos / (10000 ** (2 * i / embed_dim)))\n",
    "            pe[pos, i + 1] = math.cos(pos / (10000 ** (2 * i / embed_dim)))\n",
    "    return pe.unsqueeze(0) # Output for batch_dim propagation\n",
    "\n",
    "# Generate padding mask to prevent looking at not used tokens\n",
    "def generate_padding_mask(sequence, pad_token=tokenizer.pad_token_id):\n",
    "    mask = (sequence == pad_token).float()\n",
    "    mask = mask.masked_fill(mask == 1, float('-inf')).masked_fill(mask == 0, float(0.0))\n",
    "    return mask\n",
    "\n",
    "# Generate look ahead mask to prevent looking at future tokens\n",
    "def generate_look_ahead_mask(size):\n",
    "    mask = torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1)\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_decoder_layers, \n",
    "                 dim_feedforward, max_seq_length):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        # Create the token embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # Initialize weights with Xavier normal for stability\n",
    "        nn.init.xavier_normal_(self.embedding.weight) \n",
    "\n",
    "        # Unsqueeze to add batch dimension\n",
    "        self.pos_encoder = positional_encoding(max_seq_length, d_model).to(device)\n",
    "\n",
    "        # Transformer Decoder layers\n",
    "        self.transformer_decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            self.transformer_decoder_layer, num_layers=num_decoder_layers\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # Generate look ahead mask to prevent looking at future tokens\n",
    "        tgt_mask = generate_look_ahead_mask(src.size(1)).to(device) # check the change to 1\n",
    "        # Use padding mask to prevent looking at not used tokens\n",
    "        src_pad_mask = generate_padding_mask(src).to(device)\n",
    "        # sqrt for stabilization\n",
    "        src = self.embedding(src) * math.sqrt(d_model) # (batch_size, seq_len, d_model)\n",
    "        # add positional encoding \n",
    "        src = src + self.pos_encoder[:, :src.size(1), :] # src.size(1) = seq_len\n",
    "        output = self.transformer_decoder(tgt=src, memory=src, tgt_mask=tgt_mask,\n",
    "                                          memory_mask=tgt_mask, tgt_key_padding_mask=src_pad_mask) # Change the memory mask\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc_out(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "model = TransformerModel(vocab_size, d_model, nhead, \n",
    "                          num_decoder_layers, dim_feedforward, max_seq_length).to(device) # Watch out\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Warmup with LR scheduling (Cosine annealing)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.0001, epochs=20, steps_per_epoch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 91/91 [01:17<00:00,  1.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 8.483777046203613, LR: 0.000007\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 91/91 [01:17<00:00,  1.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 7.650610446929932, LR: 0.000017\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 91/91 [01:18<00:00,  1.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 6.771567344665527, LR: 0.000031\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 91/91 [01:24<00:00,  1.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 6.036120891571045, LR: 0.000048\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 91/91 [01:38<00:00,  1.08s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 5.4732208251953125, LR: 0.000066\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 5.196531772613525, LR: 0.000082\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 4.98106575012207, LR: 0.000093\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 4.80803108215332, LR: 0.000099\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 4.558777809143066, LR: 0.000100\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 4.343409061431885, LR: 0.000098\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 4.1233391761779785, LR: 0.000096\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 3.92221736907959, LR: 0.000092\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 3.5919346809387207, LR: 0.000087\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 3.4057118892669678, LR: 0.000082\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 91/91 [01:32<00:00,  1.02s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 3.231689691543579, LR: 0.000075\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 3.009216070175171, LR: 0.000068\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 91/91 [01:32<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 2.9581458568573, LR: 0.000060\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17:  66%|██████▌   | 60/91 [01:01<00:31,  1.03s/batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 29\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Get the avarage loss over all examples in batch\u001b[39;00m\n\u001b[1;32m     32\u001b[0m avg_epoch_loss \u001b[38;5;241m=\u001b[39m epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Example training loop with dataloader\n",
    "num_epochs = 20\n",
    "training_stats = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch}')\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=f'Epoch {epoch}', unit='batch'):\n",
    "        # Move to GPU\n",
    "        input_sequences, target_sequences = batch\n",
    "        input_sequences = input_sequences.to(device)   # To GPU\n",
    "        target_sequences = target_sequences.to(device) # To GPU\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_sequences)\n",
    "        loss = criterion(output.view(-1, vocab_size), target_sequences.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Get the avarage loss over all examples in batch\n",
    "    avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    # Update the statistics\n",
    "    training_stats['epoch'].append(epoch)\n",
    "    training_stats['train_loss'].append(avg_epoch_loss)\n",
    "    training_stats['learning_rate'].append(current_lr)\n",
    "\n",
    "        \n",
    "    print(f'Epoch: {epoch}, Loss: {loss.item()}, LR: {current_lr:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the model after training\n",
    "torch.save(model.state_dict(), 'slogan_generator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TransformerModel:\n\tMissing key(s) in state_dict: \"transformer_decoder.layers.3.self_attn.in_proj_weight\", \"transformer_decoder.layers.3.self_attn.in_proj_bias\", \"transformer_decoder.layers.3.self_attn.out_proj.weight\", \"transformer_decoder.layers.3.self_attn.out_proj.bias\", \"transformer_decoder.layers.3.multihead_attn.in_proj_weight\", \"transformer_decoder.layers.3.multihead_attn.in_proj_bias\", \"transformer_decoder.layers.3.multihead_attn.out_proj.weight\", \"transformer_decoder.layers.3.multihead_attn.out_proj.bias\", \"transformer_decoder.layers.3.linear1.weight\", \"transformer_decoder.layers.3.linear1.bias\", \"transformer_decoder.layers.3.linear2.weight\", \"transformer_decoder.layers.3.linear2.bias\", \"transformer_decoder.layers.3.norm1.weight\", \"transformer_decoder.layers.3.norm1.bias\", \"transformer_decoder.layers.3.norm2.weight\", \"transformer_decoder.layers.3.norm2.bias\", \"transformer_decoder.layers.3.norm3.weight\", \"transformer_decoder.layers.3.norm3.bias\", \"transformer_decoder.layers.4.self_attn.in_proj_weight\", \"transformer_decoder.layers.4.self_attn.in_proj_bias\", \"transformer_decoder.layers.4.self_attn.out_proj.weight\", \"transformer_decoder.layers.4.self_attn.out_proj.bias\", \"transformer_decoder.layers.4.multihead_attn.in_proj_weight\", \"transformer_decoder.layers.4.multihead_attn.in_proj_bias\", \"transformer_decoder.layers.4.multihead_attn.out_proj.weight\", \"transformer_decoder.layers.4.multihead_attn.out_proj.bias\", \"transformer_decoder.layers.4.linear1.weight\", \"transformer_decoder.layers.4.linear1.bias\", \"transformer_decoder.layers.4.linear2.weight\", \"transformer_decoder.layers.4.linear2.bias\", \"transformer_decoder.layers.4.norm1.weight\", \"transformer_decoder.layers.4.norm1.bias\", \"transformer_decoder.layers.4.norm2.weight\", \"transformer_decoder.layers.4.norm2.bias\", \"transformer_decoder.layers.4.norm3.weight\", \"transformer_decoder.layers.4.norm3.bias\", \"transformer_decoder.layers.5.self_attn.in_proj_weight\", \"transformer_decoder.layers.5.self_attn.in_proj_bias\", \"transformer_decoder.layers.5.self_attn.out_proj.weight\", \"transformer_decoder.layers.5.self_attn.out_proj.bias\", \"transformer_decoder.layers.5.multihead_attn.in_proj_weight\", \"transformer_decoder.layers.5.multihead_attn.in_proj_bias\", \"transformer_decoder.layers.5.multihead_attn.out_proj.weight\", \"transformer_decoder.layers.5.multihead_attn.out_proj.bias\", \"transformer_decoder.layers.5.linear1.weight\", \"transformer_decoder.layers.5.linear1.bias\", \"transformer_decoder.layers.5.linear2.weight\", \"transformer_decoder.layers.5.linear2.bias\", \"transformer_decoder.layers.5.norm1.weight\", \"transformer_decoder.layers.5.norm1.bias\", \"transformer_decoder.layers.5.norm2.weight\", \"transformer_decoder.layers.5.norm2.bias\", \"transformer_decoder.layers.5.norm3.weight\", \"transformer_decoder.layers.5.norm3.bias\", \"transformer_decoder.layers.6.self_attn.in_proj_weight\", \"transformer_decoder.layers.6.self_attn.in_proj_bias\", \"transformer_decoder.layers.6.self_attn.out_proj.weight\", \"transformer_decoder.layers.6.self_attn.out_proj.bias\", \"transformer_decoder.layers.6.multihead_attn.in_proj_weight\", \"transformer_decoder.layers.6.multihead_attn.in_proj_bias\", \"transformer_decoder.layers.6.multihead_attn.out_proj.weight\", \"transformer_decoder.layers.6.multihead_attn.out_proj.bias\", \"transformer_decoder.layers.6.linear1.weight\", \"transformer_decoder.layers.6.linear1.bias\", \"transformer_decoder.layers.6.linear2.weight\", \"transformer_decoder.layers.6.linear2.bias\", \"transformer_decoder.layers.6.norm1.weight\", \"transformer_decoder.layers.6.norm1.bias\", \"transformer_decoder.layers.6.norm2.weight\", \"transformer_decoder.layers.6.norm2.bias\", \"transformer_decoder.layers.6.norm3.weight\", \"transformer_decoder.layers.6.norm3.bias\", \"transformer_decoder.layers.7.self_attn.in_proj_weight\", \"transformer_decoder.layers.7.self_attn.in_proj_bias\", \"transformer_decoder.layers.7.self_attn.out_proj.weight\", \"transformer_decoder.layers.7.self_attn.out_proj.bias\", \"transformer_decoder.layers.7.multihead_attn.in_proj_weight\", \"transformer_decoder.layers.7.multihead_attn.in_proj_bias\", \"transformer_decoder.layers.7.multihead_attn.out_proj.weight\", \"transformer_decoder.layers.7.multihead_attn.out_proj.bias\", \"transformer_decoder.layers.7.linear1.weight\", \"transformer_decoder.layers.7.linear1.bias\", \"transformer_decoder.layers.7.linear2.weight\", \"transformer_decoder.layers.7.linear2.bias\", \"transformer_decoder.layers.7.norm1.weight\", \"transformer_decoder.layers.7.norm1.bias\", \"transformer_decoder.layers.7.norm2.weight\", \"transformer_decoder.layers.7.norm2.bias\", \"transformer_decoder.layers.7.norm3.weight\", \"transformer_decoder.layers.7.norm3.bias\". \n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([30522, 384]) from checkpoint, the shape in current model is torch.Size([30522, 512]).\n\tsize mismatch for transformer_decoder_layer.self_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder_layer.self_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder_layer.self_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder_layer.self_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.multihead_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder_layer.multihead_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder_layer.multihead_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder_layer.multihead_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.linear1.weight: copying a param with shape torch.Size([2048, 384]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for transformer_decoder_layer.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer_decoder_layer.linear2.weight: copying a param with shape torch.Size([384, 2048]) from checkpoint, the shape in current model is torch.Size([512, 4096]).\n\tsize mismatch for transformer_decoder_layer.linear2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm3.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm3.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 384]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for transformer_decoder.layers.0.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer_decoder.layers.0.linear2.weight: copying a param with shape torch.Size([384, 2048]) from checkpoint, the shape in current model is torch.Size([512, 4096]).\n\tsize mismatch for transformer_decoder.layers.0.linear2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm3.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm3.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 384]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for transformer_decoder.layers.1.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer_decoder.layers.1.linear2.weight: copying a param with shape torch.Size([384, 2048]) from checkpoint, the shape in current model is torch.Size([512, 4096]).\n\tsize mismatch for transformer_decoder.layers.1.linear2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm3.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm3.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 384]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for transformer_decoder.layers.2.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer_decoder.layers.2.linear2.weight: copying a param with shape torch.Size([384, 2048]) from checkpoint, the shape in current model is torch.Size([512, 4096]).\n\tsize mismatch for transformer_decoder.layers.2.linear2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm3.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm3.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for fc_out.weight: copying a param with shape torch.Size([30522, 384]) from checkpoint, the shape in current model is torch.Size([30522, 512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the weight into the model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/pokji/Desktop/for project/slogan_generator.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)   \n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m      9\u001b[0m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters())\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda_pytorch_dev/lib/python3.8/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TransformerModel:\n\tMissing key(s) in state_dict: \"transformer_decoder.layers.3.self_attn.in_proj_weight\", \"transformer_decoder.layers.3.self_attn.in_proj_bias\", \"transformer_decoder.layers.3.self_attn.out_proj.weight\", \"transformer_decoder.layers.3.self_attn.out_proj.bias\", \"transformer_decoder.layers.3.multihead_attn.in_proj_weight\", \"transformer_decoder.layers.3.multihead_attn.in_proj_bias\", \"transformer_decoder.layers.3.multihead_attn.out_proj.weight\", \"transformer_decoder.layers.3.multihead_attn.out_proj.bias\", \"transformer_decoder.layers.3.linear1.weight\", \"transformer_decoder.layers.3.linear1.bias\", \"transformer_decoder.layers.3.linear2.weight\", \"transformer_decoder.layers.3.linear2.bias\", \"transformer_decoder.layers.3.norm1.weight\", \"transformer_decoder.layers.3.norm1.bias\", \"transformer_decoder.layers.3.norm2.weight\", \"transformer_decoder.layers.3.norm2.bias\", \"transformer_decoder.layers.3.norm3.weight\", \"transformer_decoder.layers.3.norm3.bias\", \"transformer_decoder.layers.4.self_attn.in_proj_weight\", \"transformer_decoder.layers.4.self_attn.in_proj_bias\", \"transformer_decoder.layers.4.self_attn.out_proj.weight\", \"transformer_decoder.layers.4.self_attn.out_proj.bias\", \"transformer_decoder.layers.4.multihead_attn.in_proj_weight\", \"transformer_decoder.layers.4.multihead_attn.in_proj_bias\", \"transformer_decoder.layers.4.multihead_attn.out_proj.weight\", \"transformer_decoder.layers.4.multihead_attn.out_proj.bias\", \"transformer_decoder.layers.4.linear1.weight\", \"transformer_decoder.layers.4.linear1.bias\", \"transformer_decoder.layers.4.linear2.weight\", \"transformer_decoder.layers.4.linear2.bias\", \"transformer_decoder.layers.4.norm1.weight\", \"transformer_decoder.layers.4.norm1.bias\", \"transformer_decoder.layers.4.norm2.weight\", \"transformer_decoder.layers.4.norm2.bias\", \"transformer_decoder.layers.4.norm3.weight\", \"transformer_decoder.layers.4.norm3.bias\", \"transformer_decoder.layers.5.self_attn.in_proj_weight\", \"transformer_decoder.layers.5.self_attn.in_proj_bias\", \"transformer_decoder.layers.5.self_attn.out_proj.weight\", \"transformer_decoder.layers.5.self_attn.out_proj.bias\", \"transformer_decoder.layers.5.multihead_attn.in_proj_weight\", \"transformer_decoder.layers.5.multihead_attn.in_proj_bias\", \"transformer_decoder.layers.5.multihead_attn.out_proj.weight\", \"transformer_decoder.layers.5.multihead_attn.out_proj.bias\", \"transformer_decoder.layers.5.linear1.weight\", \"transformer_decoder.layers.5.linear1.bias\", \"transformer_decoder.layers.5.linear2.weight\", \"transformer_decoder.layers.5.linear2.bias\", \"transformer_decoder.layers.5.norm1.weight\", \"transformer_decoder.layers.5.norm1.bias\", \"transformer_decoder.layers.5.norm2.weight\", \"transformer_decoder.layers.5.norm2.bias\", \"transformer_decoder.layers.5.norm3.weight\", \"transformer_decoder.layers.5.norm3.bias\", \"transformer_decoder.layers.6.self_attn.in_proj_weight\", \"transformer_decoder.layers.6.self_attn.in_proj_bias\", \"transformer_decoder.layers.6.self_attn.out_proj.weight\", \"transformer_decoder.layers.6.self_attn.out_proj.bias\", \"transformer_decoder.layers.6.multihead_attn.in_proj_weight\", \"transformer_decoder.layers.6.multihead_attn.in_proj_bias\", \"transformer_decoder.layers.6.multihead_attn.out_proj.weight\", \"transformer_decoder.layers.6.multihead_attn.out_proj.bias\", \"transformer_decoder.layers.6.linear1.weight\", \"transformer_decoder.layers.6.linear1.bias\", \"transformer_decoder.layers.6.linear2.weight\", \"transformer_decoder.layers.6.linear2.bias\", \"transformer_decoder.layers.6.norm1.weight\", \"transformer_decoder.layers.6.norm1.bias\", \"transformer_decoder.layers.6.norm2.weight\", \"transformer_decoder.layers.6.norm2.bias\", \"transformer_decoder.layers.6.norm3.weight\", \"transformer_decoder.layers.6.norm3.bias\", \"transformer_decoder.layers.7.self_attn.in_proj_weight\", \"transformer_decoder.layers.7.self_attn.in_proj_bias\", \"transformer_decoder.layers.7.self_attn.out_proj.weight\", \"transformer_decoder.layers.7.self_attn.out_proj.bias\", \"transformer_decoder.layers.7.multihead_attn.in_proj_weight\", \"transformer_decoder.layers.7.multihead_attn.in_proj_bias\", \"transformer_decoder.layers.7.multihead_attn.out_proj.weight\", \"transformer_decoder.layers.7.multihead_attn.out_proj.bias\", \"transformer_decoder.layers.7.linear1.weight\", \"transformer_decoder.layers.7.linear1.bias\", \"transformer_decoder.layers.7.linear2.weight\", \"transformer_decoder.layers.7.linear2.bias\", \"transformer_decoder.layers.7.norm1.weight\", \"transformer_decoder.layers.7.norm1.bias\", \"transformer_decoder.layers.7.norm2.weight\", \"transformer_decoder.layers.7.norm2.bias\", \"transformer_decoder.layers.7.norm3.weight\", \"transformer_decoder.layers.7.norm3.bias\". \n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([30522, 384]) from checkpoint, the shape in current model is torch.Size([30522, 512]).\n\tsize mismatch for transformer_decoder_layer.self_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder_layer.self_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder_layer.self_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder_layer.self_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.multihead_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder_layer.multihead_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder_layer.multihead_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder_layer.multihead_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.linear1.weight: copying a param with shape torch.Size([2048, 384]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for transformer_decoder_layer.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer_decoder_layer.linear2.weight: copying a param with shape torch.Size([384, 2048]) from checkpoint, the shape in current model is torch.Size([512, 4096]).\n\tsize mismatch for transformer_decoder_layer.linear2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm3.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder_layer.norm3.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 384]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for transformer_decoder.layers.0.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer_decoder.layers.0.linear2.weight: copying a param with shape torch.Size([384, 2048]) from checkpoint, the shape in current model is torch.Size([512, 4096]).\n\tsize mismatch for transformer_decoder.layers.0.linear2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm3.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.0.norm3.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 384]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for transformer_decoder.layers.1.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer_decoder.layers.1.linear2.weight: copying a param with shape torch.Size([384, 2048]) from checkpoint, the shape in current model is torch.Size([512, 4096]).\n\tsize mismatch for transformer_decoder.layers.1.linear2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm3.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.1.norm3.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for transformer_decoder.layers.2.multihead_attn.in_proj_bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for transformer_decoder.layers.2.multihead_attn.out_proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 384]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for transformer_decoder.layers.2.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer_decoder.layers.2.linear2.weight: copying a param with shape torch.Size([384, 2048]) from checkpoint, the shape in current model is torch.Size([512, 4096]).\n\tsize mismatch for transformer_decoder.layers.2.linear2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm3.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for transformer_decoder.layers.2.norm3.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for fc_out.weight: copying a param with shape torch.Size([30522, 384]) from checkpoint, the shape in current model is torch.Size([30522, 512])."
     ]
    }
   ],
   "source": [
    "### Load model\n",
    "model = TransformerModel(vocab_size, d_model, nhead, num_decoder_layers, \n",
    "                 dim_feedforward, max_seq_length).to(device)\n",
    "\n",
    "# Load the weight into the model\n",
    "model_dict = torch.load('/home/pokji/Desktop/for project/slogan_generator.pth', weights_only=True)   \n",
    "model.load_state_dict(model_dict)   \n",
    "\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a graph of the model structure\n",
    "from torchview import draw_graph\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "sample_batch = next(data_iter)\n",
    "dummy_input = sample_batch[0]\n",
    "\n",
    "# graph = draw_graph(model, dummy_input, depth=2)\n",
    "# graph.visual_graph.render(filename='model_structure', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACm+0lEQVR4nOzdd3QUVRvH8e9syqb3QgIpQOgdAaX3DlIVbICCnaLYQH2lqKCi2BBFqqIiiii9N+nSew+EJEB637TdnfePyEIklIQkk/J8ztmjmb0782MJO8/euXOvoqqqihBCCCGEKDd0WgcQQgghhBDFSwpAIYQQQohyRgpAIYQQQohyRgpAIYQQQohyRgpAIYQQQohyRgpAIYQQQohyRgpAIYQQQohyRgpAIYQQQohyRgpAIYQQQohyRgpAIcq4YcOGERwcXKDXTpw4EUVRCjdQKXc/76cQQpQUUgAKoRFFUe7psXXrVq2jamLYsGEoioKLiwvp6em3PH/u3DnLe/Tpp5/me/8Gg4GJEyeW2/dXCFG+WWsdQIjyauHChbl+/vHHH9mwYcMt22vVqnVfx5k9ezZms7lAr3333XcZN27cfR3/flhbW2MwGFixYgWPPvporud+/vln7OzsyMjIKNC+DQYDkyZNAqBdu3b3/Lr7eT+FEKKkkAJQCI08+eSTuX7es2cPGzZsuGX7fxkMBhwcHO75ODY2NgXKBzkFmLW1dh8Ter2eli1bsmjRolsKwF9++YWePXvyxx9/FEuWtLQ0HB0d7+v9FEKIkkIuAQtRgrVr1466dety4MAB2rRpg4ODA2+//TYAy5Yto2fPnvj7+6PX66latSrvv/8+JpMp1z7+O2bt0qVLlsum33//PVWrVkWv19O0aVP27duX67V5jQFUFIWRI0fy119/UbduXfR6PXXq1GHt2rW35N+6dStNmjTBzs6OqlWrMmvWrHyPK3z88cdZs2YNiYmJlm379u3j3LlzPP7443m+JjExkVdeeYWAgAD0ej0hISF8/PHHlp67S5cu4e3tDcCkSZMsl5InTpxoec+cnJy4cOECPXr0wNnZmSeeeCLP9xPAbDbz5ZdfUq9ePezs7PD29qZbt27s37/f0mbDhg20atUKNzc3nJycqFGjhuXvUgghipv0AApRwsXFxdG9e3cGDx7Mk08+ia+vLwALFizAycmJsWPH4uTkxObNm3nvvfdITk5m2rRpd93vL7/8QkpKCs8//zyKovDJJ5/Qv39/QkND79rLtWPHDpYuXcpLL72Es7MzX331FQMGDODy5ct4enoCcOjQIbp164afnx+TJk3CZDIxefJkS+F1r/r3788LL7zA0qVLeeaZZyzZa9asSePGjW9pbzAYaNu2LZGRkTz//PMEBgaya9cuxo8fz9WrV/niiy/w9vbm22+/5cUXX6Rfv370798fgPr161v2YzQa6dq1K61ateLTTz+9Y6/r8OHDWbBgAd27d2fEiBEYjUa2b9/Onj17aNKkCSdOnKBXr17Ur1+fyZMno9frOX/+PDt37szXeyGEEIVGFUKUCC+//LL633+Sbdu2VQH1u+++u6W9wWC4Zdvzzz+vOjg4qBkZGZZtQ4cOVYOCgiw/X7x4UQVUT09PNT4+3rJ92bJlKqCuWLHCsm3ChAm3ZAJUW1tb9fz585ZtR44cUQH166+/tmzr3bu36uDgoEZGRlq2nTt3TrW2tr5ln3kZOnSo6ujoqKqqqg4cOFDt2LGjqqqqajKZ1AoVKqiTJk2y/FmmTZtmed3777+vOjo6qmfPns21v3HjxqlWVlbq5cuXVVVV1ZiYGBVQJ0yYkOexAXXcuHF5Pnfz+7l582YVUEePHn1LW7PZrKqqqn7++ecqoMbExNz1zy2EEMVBLgELUcLp9XqefvrpW7bb29tb/j8lJYXY2Fhat26NwWDg9OnTd93voEGDcHd3t/zcunVrAEJDQ+/62k6dOlG1alXLz/Xr18fFxcXyWpPJxMaNG+nbty/+/v6WdiEhIXTv3v2u+/+vxx9/nK1bt3Lt2jU2b97MtWvXbnv59/fff6d169a4u7sTGxtreXTq1AmTycTff/99z8d98cUX79rmjz/+QFEUJkyYcMtz1y91u7m5ATmX7eUGEiFESSAFoBAlXMWKFbG1tb1l+4kTJ+jXrx+urq64uLjg7e1tuYEkKSnprvsNDAzM9fP1YjAhISHfr73++uuvjY6OJj09nZCQkFva5bXtbq6Pw1u8eDE///wzTZs2ve1+zp07x9q1a/H29s716NSpkyXbvbC2tqZSpUp3bXfhwgX8/f3x8PC4bZtBgwbRsmVLRowYga+vL4MHD+a3336TYlAIoRkZAyhECXdzT991iYmJtG3bFhcXFyZPnkzVqlWxs7Pj4MGDvPXWW/dUWFhZWeW5XVXVIn1tQej1evr3788PP/xAaGio5WaNvJjNZjp37sybb76Z5/PVq1e/52PqdIXzHdne3p6///6bLVu2sGrVKtauXcvixYvp0KED69evv+37KYQQRUUKQCFKoa1btxIXF8fSpUtp06aNZfvFixc1THWDj48PdnZ2nD9//pbn8tp2Lx5//HHmzZuHTqdj8ODBt21XtWpVUlNTLT1+t1NYK5xUrVqVdevWER8ff8deQJ1OR8eOHenYsSPTp09nypQpvPPOO2zZsuWuWYUQorDJJWAhSqHrPUY397hlZWUxc+ZMrSLlYmVlRadOnfjrr7+4cuWKZfv58+dZs2ZNgfbZvn173n//fWbMmEGFChVu2+7RRx9l9+7drFu37pbnEhMTMRqNAJa7em+eXqYgBgwYgKqqlkmlb3b97yc+Pv6W5xo2bAhAZmbmfR1fCCEKQnoAhSiFWrRogbu7O0OHDmX06NEoisLChQuL7BJsQUycOJH169fTsmVLXnzxRUwmEzNmzKBu3bocPnw43/vT6XS8++67d233xhtvsHz5cnr16sWwYcN44IEHSEtL49ixYyxZsoRLly7h5eWFvb09tWvXZvHixVSvXh0PDw/q1q1L3bp185Wrffv2PPXUU3z11VecO3eObt26YTab2b59O+3bt2fkyJFMnjyZv//+m549exIUFER0dDQzZ86kUqVKtGrVKt/vhRBC3C8pAIUohTw9PVm5ciWvvfYa7777Lu7u7jz55JN07NiRrl27ah0PgAceeIA1a9bw+uuv87///Y+AgAAmT57MqVOn7uku5YJycHBg27ZtTJkyhd9//50ff/wRFxcXqlevzqRJk3B1dbW0nTNnDqNGjeLVV18lKyuLCRMm5LsABJg/fz7169dn7ty5vPHGG7i6utKkSRNatGgBwMMPP8ylS5eYN28esbGxeHl50bZt21vyCCFEcVHUktRlIIQo8/r27cuJEyc4d+6c1lGEEKLckjGAQogik56enuvnc+fOsXr1atq1a6dNICGEEID0AAohipCfnx/Dhg2jSpUqhIWF8e2335KZmcmhQ4eoVq2a1vGEEKLckjGAQogi061bNxYtWsS1a9fQ6/U0b96cKVOmSPEnhBAakx5AIYQQQohyRsYACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM1IACiGEEEKUM9ZaB7gfRqORQ4cO4evri04ntawQQghRGpjNZqKiomjUqBHW1qW6FCm1SvW7fujQIZo1a6Z1DCGEEEIUwD///EPTpk21jlEuleoC0NfXF8j5BfLz89M4jRBCCCHuxdWrV2nWrJnlPC6KX6kuAK9f9vXz86NSpUoapxFCCCFEfsjwLe3IOy+EEEIIUc5IASiEEEIIUc5IASiEEEIIUc6U6jGA98pkMpGdna11DHGfbGxssLKy0jqGEOWGfHaKgpLP65KvTBeAqqpy7do1EhMTtY4iCombmxsVKlRAURStowhRZslnpygM8nldspXpAvD6B5iPjw8ODg7yS1iKqaqKwWAgOjoaQKb9EaIIyWenuB/yeV06lNkC0GQyWT7APD09tY4jCoG9vT0A0dHR+Pj4yOUFIYqAfHaKwiCf1yVfmb0J5Pq4FQcHB42TiMJ0/e9TxiUJUTTks1MUFvm8LtnKbAF4nVy6KFvk71OI4iH/1sT9kt+hkq3MF4BCCCGEECK3MjsGUAghhCgpgoODeeWVV3jllVe0jlKq/bj7ErO2hRKTmkktPxcmPVyHhgFut22/6uhVPttwhoiEdCp7OjKue03a1/SxPK+qKp9vOMuifeEkp2fTJNidD/rWo7KXo6VNoiGLCctPsOlUNIoC3etWYELvOjjqc0qojGwT7/x5nOORSZyPSaVDTR9mD2lyS5bdF+L4YNVJzkWl4udmx8j2ITzSJKDw3px8kh7AciI4OJgvvvhC6xhCCFFkhg0bRt++fbWOkad9+/bx3HPPFflxgoODURQFRVFwcHCgXr16zJkzJ9/7URSFv/76q/AD3ocVR67wwcpTjOlUjVWjWlHbz5khc/cSm5qZZ/sDYfGM/vUQg5oEsHp0K7rU8eW5hfs5cy3F0ua7baHM33WJD/vW5a+XW2JvY82QeXvJyDZZ2oz59TBno1JZOLwZ84Y15Z+L8YxfeszyvFlVsbPRMaxlMC1DvPLMEh5v4JkF+2hexZPVY1rxTMvKjFt6jG1nYwrp3ck/KQBvw5yZiTkz71+qonT9H+7tHhMnTizQfgvjw6ddu3by7VUUC5NZJSYlk0RDltZRhLije73Bwdvbu9hurJk8eTJXr17l+PHjPPnkkzz77LOsWbOmWI6dXykpKSQnJ1semXc4787ZcZHBzQJ4tEkA1Xyd+bBvPextrfhtf3ie7eftvETb6t4837YqIT7OvNalBnX8Xflh9yUgp/dv3s6LjOoQQpc6Fajl58L0QQ2ISs5k/ckoAM5Hp7DtbAwfD6hHo0B3mgZ7MPHhOqw4eoWo5AwAHGyt+bBfPR5rFoi3kz7PLD/tDSPAw553e9UmxMeZoS2C6V63AnN3XLyPd+/+SAGYB2NsLJnnzmH8dw6j4nT16lXL44svvsDFxSXXttdff93SVlVVjEbjPe23OD98RPljNqukZhqJSs7gfHQqR8IT2XU+lvPRqZY2CWlZTFt3monLT/D670d48acDPDV3L/1m7qTL59v4etM5S9volAyafriRhpM30OSDjTw5Zy/vrzzJb/vDORqRSHqWKa8YQtzR8ePH6d69O05OTvj6+vLUU08RGxtreX7t2rW0atUKNzc3PD096dWrFxcuXLA8f+nSJRRFYfHixbRt2xY7Ozt+/vlnS8/jp59+ip+fH56enrz88su5isP/XoVRFIU5c+bQr18/HBwcqFatGsuXL8+Vd/ny5VSrVg07Ozvat2/PDz/8gKIod52g29nZmQoVKlClShXeeustPDw82LBhg+X5ffv20blzZ7y8vHB1daVt27YcPHgwV1aAfv36oSiK5WeAZcuW0bhxY+zs7KhSpQqTJk265/NQXmrXro2rq6vlMXXq1DzbZRnNHI9MytXDptMptAzx4mBYYp6vORSWcEuPXJvq3hwMSwAgPD6dmJTMXG1c7GxoGOBmaXMwLBEXO2vqV3KztGkV4oVOUTh0Oe/j5p0lMc8sh/49jhbKVQGoqipmg+GuD3Q6zBkZZEdFYUxMvKfX3Omhquo9Z6xQoYLl4erqiqIolp9Pnz6Ns7Mza9as4YEHHkCv17Njxw4uXLhAnz598PX1xcnJiaZNm7Jx48Zc+y3Ih09+/fHHH9SpUwe9Xk9wcDCfffZZrudnzpxp+TDz9fVl4MCBlueWLFlCvXr1sLe3x9PTk06dOpGWlnZfeUThyTKa+WbLeZ79cT9LD0ZYtl+ISaXuhHVUfWc1dSes48Epm+g0fRt9vtnJ43P28us/ly1t07NNfLPlAgt2XWLJgQjWHL/G9nOxHLqcyNmoVCIT0y1tr4+tAYhNzWTH+Vjm7rjIm0uO8vCMnbz713HL89kmM6uOXuV8dCpGk7mI34nyzZBlvO3j5ktmhdW2MCUmJtKhQwcaNWrE/v37Wbt2LVFRUTz66KOWNmlpaYwdO5b9+/ezadMmdDod/fr1w2zO/Xs1btw4xowZw6lTp+jatSsAW7Zs4cKFC2zZsoUffviBBQsWsGDBgjtmmjRpEo8++ihHjx6lR48ePPHEE8THxwNw8eJFBg4cSN++fTly5AjPP/8877zzTr7+zGazmT/++IOEhARsbW0t21NSUhg6dCg7duxgz549VKtWjR49epCSknNpdN++fQDMnz+fq1evWn7evn07Q4YMYcyYMZw8eZJZs2axYMECPvzww3zlutnJkydJSkqyPMaPH59nuwRDFiazitd/eti8nfTE3OYScExqJl5Otv9pb2u5ZByTmmHZx+32mbOP3M9bW+lws7e57XFvn+XW46Rk3vrvobiUq5tA1PR0zjR+oNiPW+PgAZRC7H0bN24cn376KVWqVMHd3Z3w8HB69OjBhx9+iF6v58cff6R3796cOXOGwMDA2+5n0qRJfPLJJ0ybNo2vv/6aJ554grCwMDw8PPKd6cCBAzz66KNMnDiRQYMGsWvXLl566SU8PT0ZNmwY+/fvZ/To0SxcuJAWLVoQHx/P9u3bgZxez8cee4xPPvmEfv36kZKSwvbt2/NVOIuicy0pg5d/OciBf7+p3jw4Wm+tIzXzxonaSqfgaGuFk94aR7017o43PnzdHGwY1iIYR70VjnprnP9tc/3//d3sLW2d9daETulBeraJs1EpnLmWwpnr/72WQs0Kzpa2oTFpvPxLTu+FrbWOEG8nalZwpsa/j7oVXW/54BUFU/u9dbd9rn0Nb+Y/3czy8wPvbyT9Nie2Byt7sPj55pafW328hfi0Wy/3X/qo532kzW3GjBk0atSIKVOmWLbNmzePgIAAzp49S/Xq1RkwYECu18ybNw9vb29OnjxJ3bp1LdtfeeUV+vfvn6utu7s7M2bMwMrKipo1a9KzZ082bdrEs88+e9tMw4YN47HHHgNgypQpfPXVV/zzzz9069aNWbNmUaNGDaZNmwZAjRo1OH78+D0VW2+99RbvvvsumZmZGI1GPDw8GDFihOX5Dh065Gr//fff4+bmxrZt2+jVqxfe3t7AjaXcrps0aRLjxo1j6NChAFSpUoX333+fN998kwkTJtw1V16cnZ1xcXEp0GvF/SlXBWBZMXnyZDp37mz52cPDgwYNGlh+fv/99/nzzz9Zvnw5I0eOvO1+7vThk1/Tp0+nY8eO/O9//wOgevXqnDx5kmnTpjFs2DAuX76Mo6MjvXr1wtnZmaCgIBo1agTkFIBGo5H+/fsTFBQEQL169fKdQRS+XRdiGb3oELGpWTjbWTO6QzWaVr7xBaGCix1bX2+Ho94aJ701dja628795WBrzcSH69zTcXPGvOb0BDYKdKdRoHuu503mG18O0rNNNKjkytmoVNKzTZy8mszJq8mW51/vUp2RHaoBOZeW152IomYFZ6r7OuNqb3PP74Uo3Y4cOcKWLVtwcnK65bkLFy5QvXp1zp07x3vvvcfevXuJjY219Pxdvnw5VwHYpMmtd3jWqVMn12oXfn5+HDt27JZ2N6tfv77l/x0dHXFxcbEsn3bmzBmaNm2aq32zZs24F2+88QbDhg3j6tWrvPHGG7z00kuEhIRYno+KiuLdd99l69atREdHYzKZMBgMXL58+Q57zXkPd+7cmasINZlMZGRkYDAYinSYkbuDLVY65ZYbPmJSM2877s7bSU9satZ/2mdZvhB6O9lZ9uHjYpdrn7X9XG7aR+5jGk1mEtOzb3vc22e5Nbuz3ho7G21WSSlXBaBib0+Ngwfuqa2qqmRduoQ5PR1rLy9sfHzu/qI7HLcw/ffDJzU1lYkTJ7Jq1SpLMZWenn7Xf8x3+vDJr1OnTtGnT59c21q2bMkXX3yByWSic+fOBAUFUaVKFbp160a3bt0sl58bNGhAx44dqVevHl27dqVLly4MHDgQd3f32xxNFDVVVZn1dyifrD2NWYVafi5892Rjgjwdc7WzttIR7OV4m70UHSvdjSKzYYAby0a2wmxWCU8wWHoJT0elcPZaCrX8bvQuHLqcyP9uunzs72pH9eu9hb7OtKjqRQVXO0TeTk7uetvndP8p/A/8r9M9t93xVvv7C3YPUlNT6d27Nx9//PEtz11fq7Z3794EBQUxe/Zs/P39MZvN1K1bl6ys3EWEo+Otv/M2Nrm/TCiKcsul48J4zb3w8vIiJCSEkJAQfv/9d+rVq0eTJk2oXbs2AEOHDiUuLo4vv/ySoKAg9Ho9zZs3v+XP+V+pqalMmjTplt5PADu7ov13Y2uto25FV3adj6VrnZxeSbNZZdf5OIa0CMrzNY2C3Nl1PpbhrSpbtu04F0PjoJxzS4CHPd7Oenadj6OOvysAKRnZHA5P5MmHcvbZOMiN5AwjxyKSqFcpp82uC3GYVZVGgW73nL9RkBtbT+e+43fHuVgaBWl3nitfBaCi5OtSrG2lSmSFh6Omp6Po9SglZC3D/374vP7662zYsIFPP/2UkJAQ7O3tGThw4F3/MRfVh09enJ2dOXjwIFu3bmX9+vW89957TJw4kX379uHm5saGDRvYtWsX69ev5+uvv+add95h7969VK5c+e47F4Vu+7lYPlpzGoABjSvxQd+62NuWjN//29HpFII8HQnydKRLnQp5tnHWW9O+hjdnrqVwJSnD8th6JueD+evHGtG7gT+QM7bQWqfIagY3cbC991NGUbUtqMaNG/PHH38QHByMtfWtx4uLi+PMmTPMnj2b1q1bA7Bjx44iz3U7NWrUYPXq1bm2XR+Llx8BAQEMGjSI8ePHs2zZMgB27tzJzJkz6dGjBwDh4eG5boaBnPODyZT7En7jxo05c+ZMrt7E4jSiVWVe+/0I9Sq50TDAlbk7LmHIMvLIAzlz6Y1dfBhfVzve6lYTgGdaBjNo1h5m/x1K+5o+rDhyhWORSUztn9P5oSgKz7SszNebzxHs5UiAhz2frT+Lr4ueLrV9AQjxcaZtdW/GLT3Kh/3qYTSZmbD8BL3r++N7U6/huagUskxmktKzSM00cuJKEoClsHzywSB+3BXG1NWneKRJALsvxLLq2FXmDcvdy1ucylUBmF86FxcUW1vUrCxMCQlYe+U9v4/Wdu7cybBhw+jXrx+Q8y3t0qVLxZqhVq1a7Ny585Zc1atXt1wWsba2plOnTnTq1IkJEybg5ubG5s2b6d+/P4qi0LJlS1q2bMl7771HUFAQf/75J2PHji3WP4fI0aa6N08+FEgtPxcebxZYZoqgFiFetPj3Tryk9Owb4wv/fdT2v9Fb+NOeMObtvEiPen70qudP3YouZeZ9KMuSkpI4fPhwrm3X78qdPXs2jz32GG+++SYeHh6cP3+eX3/9lTlz5uDu7o6npyfff/89fn5+XL58mXHjxmnzhwCef/55pk+fzltvvcXw4cM5fPiw5aaS/P4ejhkzhrp167J//36aNGlCtWrVWLhwIU2aNCE5OZk33ngD+/9cqQoODmbTpk20bNkSvV6Pu7s77733Hr169SIwMJCBAwei0+k4cuQIx48f54MPPiisP/pt9W7gT3xaFp9vOEtMSia1/F344ZlmeDvnXIqNTEzP9d48EOTBl4Mb8dn6M0xbd4ZgLwe+f6oJNW4aQ/xC2yqkZxkZv/QYyRnZNA1254enm+W6LPvl4Ia8t+wET8zeg05R6Fa3wi3DWYbN35frRraeX+V8ebg+jjXAw4F5w5ry/sqTzN95iQqudnzUvx5tq3sX/ht1j6QAvANFUbD28iL7yhWMsXFYeXig6ErejdPVqlVj6dKl9O7dG0VR+N///ldkPXkxMTG3fLj6+fnx2muv0bRpU95//30GDRrE7t27mTFjBjNnzgRg5cqVhIaG0qZNG9zd3Vm9ejVms5kaNWqwd+9eNm3aRJcuXfDx8WHv3r3ExMRQq1atIvkziLytOXaVh6p4Wm7c+KBv2R6H6WpvQ9NgD5oG533T08ZTUYTHpzNrWyiztoUS4GEvxWApsHXrVsv44uuGDx/OnDlz2LlzJ2+99RZdunQhMzOToKAgunXrhk6XM3b1119/ZfTo0dStW5caNWrw1Vdf0a5dO03+HJUrV2bJkiW89tprfPnllzRv3px33nmHF198Eb0+fzc11a5dmy5duvDee++xevVq5s6dy3PPPUfjxo0JCAhgypQpuaYYA/jss88YO3Yss2fPpmLFily6dImuXbuycuVKJk+ezMcff4yNjQ01a9bMdYNJURvaIpihLYLzfO7mG4uu61nfj571/W67P0VRGNulBmO71LhtGzcHW756rNFtnwfYOa7DHZ8HaF7Vk9VjWt+1XbFRS7Hw8HAVUMPDw295Lj09XT158qSanp5+X8cwm0xq+qlTquHYMTU7Pv6+9pVf8+fPV11dXS0/b9myRQXUhISEXO0uXryotm/fXrW3t1cDAgLUGTNmqG3btlXHjBljaRMUFKR+/vnnlp8B9c8//8y1H1dXV3X+/Pm3zdO2bVsVuOXx/vvvq6qqqkuWLFFr166t2tjYqIGBgeq0adMsr92+fbvatm1b1d3dXbW3t1fr16+vLl68WFVVVT158qTatWtX1dvbW9Xr9Wr16tXVr7/+Os8MhfX3Km7IzDapE5YdV4PeWqkOmbtXNZrMWkcqEdIys9WVR66oL/10QK3x7mo16K2VlkfHz7aq2UaT1hGLhPwbK7k++OADtVKlSlrHuGd3+l260/lbFA9FVUvvXBsREREEBAQQHh5OpUqVcj2XkZHBxYsXqVy58n0PTjXGxJAdFYViq0dfLUS++WuoMP9eRc4ULy/9fICD/05oOrJ9CK92rp7rJguRM0/dltMxrD52lU2no2hZ1Yu5N43dmbfjIk2DPcpEz6D8Gys5Zs6cSdOmTfH09GTnzp2MGjWKkSNHFsvl1sJwp9+lO52/RfGQS8D3wMrDA2NMLGpWJuaUFKxkziJRBvx3ipfPH21Ip38HPovcHGytLZeSDFnGXHPWhccbmLzyJACBHg70qOdHz3p+ZaIYFNo6d+4cH3zwAfHx8QQGBvLaa6/ddqJkIfJLCsB7oFhZ5RSBsTEYY2LQOTvLB7sotdR7nOJF5M3B1jrXXauZRjM96/mx6XQUl+MNfLftAt9tu0CghwPd61VgUJMAqnjfOvecEHfz+eef8/nnn2sdQ5RRmhaAptQ0Yr76kpSNGzHFxWNXqxa+77yNfQmcBNja0wNjXCzm9HTMBgNWecwDJURpkJpp5Oe9YZjV0jPFS0kW4uPEN080vuUy8eV4A7O2hVLX39VSAGYaTdha3X6ybCGEKC6aFoBX//cumefOUfHjj7H28SFp+QouP/0MVVatxMa3cC5FFdYQR8XGBit3d0zx8RhjYqQA1EgpHrJaYjjb2fDtEw9wJCKxTE3xorX/XibecjqGtSeu0aHmjUnkv98Wym8Hwi2XietVdC2x77/8WxP3S36HSjbNCkBzRgYp6zdQ6ZsZOPy73I33qJGkbtlCwqJF+Lzyyi2vyczMJDPzxlIq1xeuzsv1SY4NBsMt8xsVlLWnJ6b4eMypqZgzMtDJAOliZzAYgFsnsRZ3tuxwJJnZZh5tmjNhat2KrtSt6KpxqrLr5mLwZptOR98ytczQ5sE8/mBgsUyGfC+K4rNTlE/yeV2yafaJoxpNYDKh+898RoqdHekHDub5mqlTpzJp0qR72r+VlRVubm6Wpc0cHBwK5Zt2tqMj5pQUsq9exdbv9nMLicKlqioGg4Ho6Gjc3Nxyrbkpbi/LaGbK6lMs2HUJWysdDQLcck2CKorXL88+yNYzMaw6epXN/xaDH6w6xcytF3i2dRVebFdV64hF9tkpyg/5vC4dNCsArZwcsW/YkNiZ32JbpSrWXp4kr1pF+uHD2AYG5vma8ePH51oZIjIy0rK2YV4qVMhZDqqg69vmRc3OxhgTAzExWKemouSxpJAoOm5ubpa/V3Fn/53i5bk2VQjxkZsRtORga02Pen70qJdzmXjFkSvM3HqBsDgDp68lax3Poig+O0X5I5/XJZum8wBmXb7M1bffwbB/P1hZYVe7NrbBwWScOEHV1avu+vp7nUfIZDKRnZ1daLmvvP0O6YcO4dK7N94vvVho+xV3ZmNjI98k79HuC3GMWnRQpngpBYwmM6uOXaWOvwshPjm9s6ExqSz65zLPtq6Cj4t2Q00K+7NTlB93+7yWeQC1p2n3lW1gIEE/LcRsMGBKTcXGx4eIV1/FJqBwfxmsrKwKtXDwffQRLq9eTdqPP+I3bCjWHnkvJSWEFuZsD2XqmtOYzCo1Kzjz3ZMPEOwlNy2VVNZWOvo0rJhr28ytF1hyIIIfdocxuGkAz7etSkW34h+PV9ifnUKIkqNELGyrc3DAxscHU1ISaTt24tyho9aR7sjhwQexq1sXNSODhJ9+0jqOELlkZJswmVX6N67Iny+1lOKvFOpV348HgtzJMpr5cXcYbT/ZwptLjnAxNk3raEKIMkLTS8Cp23cAKraVK5MVFkb0tE9R9LYE//QTyj3cNaRlF3Ly2nVEvvIKOldXqm3ehE6mhREaUlXVMlDfbFbZciaaDjV9ZPB+KaaqKntC45mx5Rw7z8cBoFPgyYeCmNynrsbphLg/cglYe5r2AJpTU7g2+X1Cu/fgyrhxODRuTOCcOfdU/GnNuXMnbIOCMCclkfD771rHEeXYssORDPh2F+lZJgB0OoWOtXyl+CvlFEWheVVPfh7xEH+82IIONX0wq+DpqL/7i4UQ4i407QG8X1p/g0j47TeuvTcB6woVCFm/DsXWttgziPLr5ileAMZ3r8nzbbWfRkQUneORSQS4O+DqkPMlefPpKH7cHcbI9iE0CZaxyKL00Pr8LUrIGMDSyrVvX6y9vTFeu0bSyrvftSxEYUnNNPLY7D2W4m9k+xBGtK6ibShR5OpWdLUUfwDfbr3A1jMxDPxuN4O/383O87Gy+oIQ4p5IAXgfdLa2eAwdAkDc3LmoZrPGiUR5MXX1KQ6EJeBsZ82cIU14vWsNrHRyybe8mTawAYObBmBjpbAnNJ4n5uyl/7e72HQqSgpBIcQdSQF4n9wGDULn5ETWhQukbt2qdRxRDuw6H8vPey8DMOupB2R+v3Is2MuRjwbUZ9sb7RnWIhi9tY5DlxMZ/sN+Xll8WOt4QogSTArA+2Tl7Iz7Y48BEPf9bPnWLYqUqqpMXnkSgCcfCqRFVS+NE4mSwN/NnokP12HHWx14vm0VHG2t6HzTF4NMowmjSa5QCCFukAKwEHgMeQrF1pb0w4dJP3BA6ziiDFMUhTlDmzCgcSXGda+ldRxRwng76xnfvRY7x3Wge90ba5Uv3B1Gh8+2seify2QZpRAUQkgBWCisvb1x7dsXgLjZc7QNI8q8Su4OfPZoA5z0sg61yJubg61lTKiqqvxxMJLL8QbGLz1Gty//ZveFOI0TCiG0JgVgIfEc/gzodKRu20bGmbNaxxFljCHLyK4LsVrHEKWQoij88WJz/terNl5OekJj0nhs9h5e++0IcamZWscTQmhECsBCYhsUhHOXLgDEzZVeQFG4Pll7hsdn72X6+jNaRxGlkIOtNcNbVWbTa2158qFAFAX+OBhBx+nb2HQqSut4QggNSAFYiDxHjAAgedVqsiMjNU4jyop/Lsbzw+5LADwgk/2K++Bqb8MHfeux9MUW1PJzISXDiJ+rvdaxhBAakAKwENnXrYNji+ZgMhE3f4HWcUQZkJ5l4s0lR1BVGNQkgLbVvbWOJMqARoHurBjZkp9HPEhtfxfL9m1nYyxLCgohyjYpAAvZ9V7AxCVLMCYkaJxGlHafrT/DpTgDFVzseKeX3PUrCo+1lY6Hqnhafj5zLYXhC/bR5YttbD0TrWEyIURxkAKwkDk0b45dnTqoGRkk/PSz1nFEKXYgLJ65Oy8CMLV/PVzsbO7yCiEKLsGQhbeznvD4dIbN38fLvxwkOjlD61hCiCIiBWAhUxQFz2dzegETfvoJs8GgcSJRGmUZzbyx5CiqCgMaV6J9TR+tI4ky7qEqnmwY25bhrSqjU2DV0at0/GwbP+6+hMksE9wLUdZIAVgEnDt3xiYoEFNSEolLlmgdR5RCNlYKYztXp5afC+/1qq11HFFOOOmt+V+v2iwf2YoGlVxJyTTy3rITDJm3V1Y5EqKMkQKwCChWVng+MxyAuPkLULOzNU4kShtFUehV35/Vo1vh6iCXfkXxqlvRlaUvtWRynzo4663pUNMXRVG0jiWEKERSABYR1759sPLywnj1KkmrVmkdR5QSGdkm4tOyLD/LSVdoxUqnMKR5MJteb8vQ5kGW7XtD41h/4pqGyYQQhUEKwCKi0+vxGDoEgPi5c1HNsv6muLsvN52j8/RtbDwpk/OKksHH2Q5rq5xTRUa2iXFLj/HcwgM8++N+riSma5xOCFFQUgAWIffBg9E5OZF57jypW7dpHUeUcEfCE5m17QJxaVkYZdC9KKG6162AtU5hw8koOk3fxpztoRhN8gVXiNJGCsAiZOXsjPvgQQDEzZHl4cTtZRpNvLHkCGYVejfwp1vdClpHEuIWdjZWvNmtJqvHtKZpsDuGLBMfrDrFwzN2cjg8Uet4Qoh8kAKwiLkPGYJiY0P6wYMYDhzQOo4ooWZsPs/ZqFQ8HW2Z9HAdreMIcUfVfZ1Z/FxzPh5QD1d7G05eTabfzJ0cj0zSOpoQ4h5JAVjEbHx8cO3bF4C42dILKG51PDKJmVsvAPB+37p4ONpqnEiIu9PpFAY1DWTTa23p36gi7ap7U+emZeWEECWbFIDFwOOZp0FRSN26lYyzZ7WOI0qQLKOZ138/gsms0rOeHz3q+WkdSYh88XLSM31QQ2Y91cRy13pCWhajFh3icpxMhC9ESSUFYDHQV66Mc5cuAMTPnadxGlGSGM1mGga44eFoy6Q+culXlF621jdOJ5+sO8OKI1fo/Pk2Zm27gFluahKixJECsJh4jshZHi5p1Sqyr1zROI0oKRxsrfloQH02jm2Ll5Ne6zhCFIrn2lShZYgnmUYzU9ecZuj8f4hNzdQ6lhDiJlIAFhP7enVxaP4QGI3ELVigdRyhMZNZzbW0loz7E2VJZS9Hfhr+IB8PqIedjY7t52Lp/uV2dl2I1TqaEOJfUgAWo+u9gIm/L8GYkKBxGqGlmVvOM3T+PiJlIl1RRilKzk0iy0e2opqPEzEpmTw5Zy8rjsgVECFKAikAi5Fjixboa9dCTU8n4edftI4jNHL6WjJfbT7H32dj2H8pXus4QhSp6r7OLB/ZikebVKKCix2tq3lpHUkIgRSAxUpRFLyefRaAhJ9+wmyQO+TKG6PJzBu/HyXbpNKpli8PN/DXOpIQRc7e1opPBjZg5ejWuDnkDHdQVZVTV5M1TiZE+SUFYDFz7tIFm8BATImJJP6xVOs4opjN+juUY5FJuNhZM6VfXcu0GUKUBzePdf39QATdv9zOJ2tPy1JyQmhACsBiplhZ4fnM0wDEzZ+Hmp2tcSJRXM5GpfDlxnMATHy4Dj4udhonEkI7Z6+lADBz6wUGf7+HKzIeVohiJQWgBlz79cPKywvjlaskr1mjdRxRDHIu/R4hy2SmQ00f+jWqqHUkITT1bq/afPN4Y5z11uwPS6DHV9vZeDJK61hClBtSAGpAp9fj8dRTQM7ycDdPByLKpuiUTFIyjTjbWTOlXz259CsE0LO+H6tGt6Z+JVcSDdmM+HE/H6w8SZZRLgkLUdSkANSI+2OD0Tk6knnuHKnbtmkdRxQxfzd7Vo9uzU/DH6SCq1z6FeK6QE8Hfn+hOc+0rAzA3J0XORaZqG0oIcoBKQA1YuXigtvgQQDEzZmjcRpRHOxsrGgQ4KZ1DCFKHL21Fe/1rs3sIU14q1tNHgjy0DqSEGWeFIAa8hgyFMXGhvT9BzAcPKR1HFEEfth1ie//voBJ1kIV4q461/blhbZVLT9fik3jg5Unycg2aZhKiLJJCkAN2fj64Nq3DyC9gGVRaEwqU1afYsrq06w/cU3rOEKUKmazyuhfDzFnx0X6z9zFxdg0rSMJUaZIAagxj2eeAUUhdfNmMs+f1zqOKCQms8qbS46SaTTTupoX3epW0DqSEKWKTqcwtnN1PBxtOXk1mV5fbWfZ4UitYwlRZkgBqDF95co4d+oEQNycuRqnEYXlh12X2B+WgKOtFVP7y12/QhREuxo+rBnTmgcre5CWZWLMr4d5a8lR0rPkkrAQ90sKwBLA87mc5eGSli8n4/RpjdOI+3UpNo1P1uX8Pb7dsxaV3B00TiRE6eXrYsfPIx5kdMdqKAos3h9On292cDVJJo4W4n5IAVgC2Nerh3P3bmA2c+39D2RewFLMbFZ584+jZGSbaVHVk8ebBWodSYhSz9pKx9jO1flp+IN4O+uxt7XG01GvdSwhSjUpAEsI3zffRLG3J/3AAZJXrNA6jiigE1eSOXQ5AQdbKz4eUF8u/QpRiFqGeLF6dGtmPtEYW+uc01e2yUxaplHjZEKUPpoWgKrJRPSXX3K+YydON2jI+c5diJk5s1z2gNn4+eH14osARE2bhik1VeNEoiDqVXJlxahWfPZIAwI85NKvEIXN21lPRTd7y8+frT9L7xk7OHklWcNUQpQ+mhaAcbPnkLjoV3z/9y5VVq3C57XXiJ8zl4SFP2kZSzMew4ZiGxSEKSaW2BnfaB1HFFDNCi50r+endQwhyrzUTCPLD0cSGpNG35k7+XlvWLnsQBCiIDQtANMPHcKpYwec27XDtlJFXLp1xbFlS9KPHdMylmZ0trb4vvsuAPELF5J57pzGicS92nUhltPXpAdCiOLkpLdm5ejWdKjpQ5bRzDt/HmfUokMYsuSSsBB3o2kBaN+oEYbde8i8eBGAjNOnMRw8iFOb1nm2z8zMJDk52fJISUkpzrjFwql1K5w6dQSTiWsffCjfZksBo8nM+KXH6PbFdtbJhM9CFCsPR1vmDGnCOz1qYa1TWHn0KoNm7SEqOUPraEKUaJoWgJ7PPYtLzx6E9ujJqbr1uNivPx5DhuDau3ee7adOnYqrq6vlUbt27WJOXDx8x41H0esx7N1Lytq1WscRd7H8yBXC4gx4ONrSupqX1nGEKHd0OoVn21Rh0XMP4eFoy7HIJB6dtZsso1nraEKUWNZaHjx5zRqSVqzE/9Np6EOqkXn6FFFTpmLt44Nbv763tB8/fjxjx461/BwZGVkmi0DbShXxfO5ZYr+eQdRHH+PUpg06R0etY4k8mMwqMzbnrOAyonVlHGw1/SclRLnWNNiDv15qyfAf9jG6YzXLncKi7Phx9yVmbQslJjWTWn4uTHq4Dg0D3G7bftXRq3y24QwRCelU9nRkXPeatK/pY3leVVU+33CWRfvCSU7PpkmwOx/0rUdlrxvn3ERDFhOWn2DTqWgUBbrXrcCE3nVw1N/4vD91NZn3lh3nSEQSno62DG0RnGtda4C5Oy7y854wIhPT8XC0pXtdP97sVgM7G6vCe4PyQdN/HdHTPsXz2RG49uyJXY3quPbpg8ewocR9/32e7fV6PS4uLpaHs7NzMScuPp7Dh2NTqRLGqChiv5uldRxxG6uOXSU0Ng03BxuGNA/WOo4Q5V6gpwOrRremdwN/y7aYlEwZTlMGrDhyhQ9WnmJMp2qsGtWK2n7ODJm7l9jUzDzbHwiLZ/SvhxjUJIDVo1vRpY4vzy3cz5lrN4aPfbctlPm7LvFh37r89XJL7G2sGTJvLxnZN1abGfPrYc5GpbJweDPmDWvKPxfjGb/0xr0KKRnZPDX3Hyq62bNyVCvG96jFFxvP8svey5Y2yw5H8vHa04zpVI2NY9vy8YD6rDx6hWnrzhTBO3VvtJ0GJj0dRfefCDorMEu3vc7ODt+33wYgbsECMkMvapxI/JfZrPL1ppwbdYa3rIyTXnr/hCgJbu75u5aUQe+vd/D2n8fINsm5pTSbs+Mig5sF8GiTAKr5OvNh33rY21rx2/7wPNvP23mJttW9eb5tVUJ8nHmtSw3q+Lvyw+5LQE7v37ydFxnVIYQudSpQy8+F6YMaEJWcyfqTUQCcj05h29kYPh5Qj0aB7jQN9mDiw3VYcfSKZZzpX4evkG0y88nABlT3debhBv4Ma1GZOTtCLVkOhCXQJMidPg0rEuDhQJvq3jzcwJ8j4YlF+p7diaYFoFP79sR+N4uUrVvJiogkecMG4hcswLlzJy1jlRhO7dvh2LYNZGcT9aHcEFLSrD1xjXPRqTjbWTO0ZbDWcYQQedh7MY6olAwW/RPO0Hn/kGTI1jqSuElKSkqumzszM/PuzcsymjkemUTLkBvjrHU6hZYhXhwMS8zzNYfCEnK1B2hT3ZuDYQkAhMenE5OSmauNi50NDQPcLG0OhiXiYmdN/UpuljatQrzQKQqHLidajtOsskeuLx5tqnsRGpNm+X17IMidY5FJHP634LscZ2DLmehcl6OLm6YFoO+77+LctQvXJk8mtGdPoj+ZhtugR/EePVrLWCWGoihUePttFBsb0nbuJGXjRq0jiZtkGk14OtryTMvKuNjZaB1HCJGHPg0rMmdIExxtrdh1IY5+3+7kUmya1rHEv2rXrp3r5s6pU6fm2S7BkIXJrOLllHsJQG8nPTG3uQQck5qJl5Ptf9rbWi4Zx6RmWPZxu33m7CP389ZWOtzsbe7Y5vo+rx+jT8OKjO1cnUe+20XI26tpM20LD1Xx5OX2IXlmLw6aXrOycnKkwttvU+HfS53iVrZBQXgMf4a472YRPfUjnFq1Qmdvf/cXiiLXr1ElutXxwyw9s0KUaB1r+bLkxRYMX7DPMmn0rCcf4MEqnlpHK/dOnjxJxYoVLT/r9WVzjefdF+L4ZssF3u9Tl4aBblyKNTB5xQm+2nSO0R2raZJJbpEqBbyeew5rPz+yr1whbvZsreOIm9jbWuW6E0wIUTLV8nPhr5db0qCSK4mGbJ6cu5e/z8ZoHavcc3Z2znVz5+0KQHcHW6x0yi03fMSkZt7Sg3edt5Oe2NSs/7TPsvTWeTvZWfZxu33m7CP380aTmcT07Du2ub7P68eYvuEM/RtXZHCzQGpWcKFb3Qq80a0GM7eex2zWphNBCsBSQOfggO+4cQDEzZlL1uXLd3mFKEp7Q+NYe/yqZv9ohRAF4+Nix+Lnm9Oznh+VvRxpFOimdSRxj2ytddSt6Mqu87GWbWazyq7zcTQOcsvzNY2C3HO1B9hxLobGQe4ABHjY4+2sZ9f5OMvzKRnZHA5PtLRpHORGcoaRYxFJlja7LsRhVlXL70+jIHf+uRif6yajHediqeLtiKtDzvCg9GwTipI7n+7fDVqdSaQALCWcu3TGsUVz1KwsoqZ+pHWccktVVaasPsULPx1k9vbQu79ACFGi2NlY8fVjjVj8XHOc/x27q6oqmUbTXV4ptDaiVWUW7QtnyYEIzken8M5fxzFkGXnkgQAAxi4+zMdrT1vaP9MymG1nY5j9dyjno1P5fMNZjkUmMfTfKbsUReGZlpX5evM5NpyM4vS1ZMb+dgRfFz1davsCEOLjTNvq3oxbepTD4YnsvxTPhOUn6F3fH1+XnN69Pg39sbHS8daSo5yNSmHFkSvM33mJEa2qWLJ0rOnLz3sus/zIFcLjDWw/F8P0DWfpWMsXK91/KsNiIteuSglFUfB9911CH+5D6pYtpGzdinO7dlrHKnf+PhfLkYgk7Gx0DHigktZxhBAFoNMpuDveuDlgzvaLLD9yhTlDm1hO6qLk6d3An/i0LD7fcJaYlExq+bvwwzPN8HbOuRQbmZiOclM32wNBHnw5uBGfrT/DtHVnCPZy4PunmlCjwo05hF9oW4X0LCPjlx4jOSObpsHu/PB0s1yTM385uCHvLTvBE7P3oFMUutWtwMSH61ied7GzYeHwZry37Di9vt6Bh4MtoztW4/EHAy1tRnUIQVHgs/VnuJaUgaejLR1r+fJ61xpF+ZbdkaKW4rlFIiIiCAgIIDw8nEqVysfJOGraNOLnzsMmMJAqK5ajK6MDZksiVVUZ8O0uDl5OZESryrzbq+ytQiNEeZOckU2HT7cSm5qFn6sdc4Y2oY6/q9axyrzyeP4uaeQScCnj9eJLWPv4kH35MvHz5mkdp1zZdSGOg5cT0VvreK5Nlbu/QAhR4rnY2fDHiy2o6u3I1aQMHvluNxv+nQRYiLJMCsBSxsrJEZ833wQgdtb3ZEdGapyo/Pjy31U/HmsWiI9cJhKizAjydGTpSy1pFeKFIcvEcwv3M/vvUJl8X5RpUgCWQi49e+DQtClqRgZRH32sdZxyYU9oHP9cjMfWSnfLAt9CiNLP1d6G+U835fEHA1FV+HD1Kf637LjWsYQoMlIAlkLXbwjByoqUDRtI3bFT60hlnrVOoX4lVx5tWokKrtL7J0RZZGOl48O+dXm3Zy0UBar5ON/9RUKUUnITSCl2bcoUEn5ciG3lylRZ9heKre3dXyQKLGeqCHOuu8OEEGXTmWspue4WVVU11x2m4v6U9/N3SSA9gKWY96hRWHl6knXxIvE//qh1nDJPURQp/oQoJ24u/pIM2Qz8bjd7Q+Pu8AohShcpAEsxK2dnfF5/HYCYmd+SHSV3rhW2oxGJfLPlPCkZ2VpHEUJo5ItNZzkQlsCTc/ey5ECE1nGEKBRSAJZyrn0exr5hQ1SDgeiPP9E6TpnzxcZzTFt3ho/WnL57YyFEmfRWt5r0rOdHtknl9d+P8Mna07IUpCj1pAAs5RSdjgrv/Q8UheTVq0nb+4/WkcqMYxFJbD4djU6BEa1l3j8hyqvry8eN6hACwMytFxi56CDpWbJ8nCi9pAAsA+xq18Zt8CAAoj54HzVbLlcWhq8358z716dhRSp7OWqcRgihJZ1O4bUuNZj+aANsrXSsPnaNQd/vJjo5Q+toQhSIFIBlhM+YMVi5uZF57jwJv/yidZxS7+SVZNafjEJR4OX2IVrHEUKUEP0bV+KnEQ/i7mBDfFoWOp3cGSxKJykAywgrNze8x74KQMzXMzDGxGicqHSbsSWn969nPT9CfJw0TiOEKEmaVfbgr5dbMn9YU7ycZD12UTpJAViGuA0ciF29ephTU4n+9DOt45RaZ6NSWH3sGgCjOlTTOI0QoiQK8nSkmu+NqWJWHr3CjnOxGiYSIn+kACxDFJ2OCv97F4CkZcswHDyocaLSyd7Gir4N/elZ3y/XXGBCCJGXA2EJvPLrYZ5ZsI+1x69qHUeIeyIFYBljX78+rgMHAHDt/Q9QTXKXWn4FeDjwxeBGfD24kdZRhBClQN2KLnSq5UuWycxLPx/kt33hWkcS4q6kACyDfMaORefiQuapUyQsXqx1nFJLBncLIe6F3tqKGY83YlCTAMwqvPnHUWb/Hap1LCHuSArAMsjawwPvMaMBiPniS4zx8RonKh0uxaYx9rfDhMakah1FCFHKWFvp+GhAPZ5vkzNn6IerTzFt3WlUVSaMFiWTFIBllPvgwehr1cKcnEzM559rHadU+GbLeZYejOSDVae0jiKEKIUURWF8j1q81a0mAN9sucDa49c0TiVE3qQALKMUKyvLDSGJS/4g/ehRjROVbOHxBpYeigRgZAeZ908IUXAvtqvKlH71GNw0gG51K2gdR4g8SQFYhjk0boxrnz6gqlyb/D6q2ax1pBJr5tbzmMwqrat50TjQXes4QohS7vEHA/loQH0UJWcscUa2CUOWUeNUQtwgBWAZ5/P6a+gcHck4fpzEP/7QOk6JFJmYzpIDEQCM6Sjz/gkhCpfRZGbMr4d4au4/JBlkqU5RMkgBWMZZe3vjNWokADGfTceUmKhtoBLou60XyDapNK/iSZNgD63jCCHKmLB4A7svxHEgLCFn/eAUWT9YaE8KwHLA44kn0FcLwZSYSMxXX2kdp0S5lpTB4n/n7BotvX9CiCJQ1duJxc83x9tZz+lrKTzy3W7C4w1axxLlnBSA5YBiY4Pvu/8DIOHXxWScPKlxopLDUW/FqA4hdK7ty0NVpPdPCFE0avm5sOSF5gR42BMWZ2DAt7s4cy1F61iiHJMCsJxwfLAZLj16gNksN4TcxNnOhlEdqzF7SBPLYG0hhCgKQZ6OLHmhBTV8nYlOyeTRWbs5eDlB61iinJICsBzxefMNFAcH0g8fJmnZcq3jCCFEuePrYsfi5x+iUaAbmUaTTBQtNCMFYDliU6ECXi++AED0p59iSim/lx9iUzMZ/P1uNp+Okg9gIUSxcnOw5afhD/LLsw/xQJAMPRHakAKwnPEcOhTb4GBMcXHEfP211nE0M2f7RfaExvPlxnNaRxFClEOOeutcc46euJLE7/vDNUwkyhspAMsZxdYW33dzVghJ+PkXMkPL34Ll8WlZ/Lj7EpBz56+M/RNCaCk6JYOh8/7hjSVHmbXtgtZxRDkhBWA55NSqJU4dOoDJRPT06VrHKXbzdlzEkGWijr8LHWr6aB1HCFHOeTvpGfhAAABT15zm47WnZWiKKHJSAJZTPmNfBZ2O1I2bMBw8qHWcYpNkyGbBrksAjOogvX9CCO0pisK47jUZ170mAN9uvcDbfx7HZJYiUBQdKQDLKX1ICG4D+gMQPe3TcvNtc97Oi6RmGqlZwZkutX21jiOEEBYvtK3K1P71UBRY9M9lRi86RJZRpuwSRUMKwHLMa+QoFDs70g8dImXjRq3jFLnkjGzm7bwI5PT+6XTS+yeEKFkeaxbIjMcaY2OlsOrYVWZslhvVRNGQArAcs/H1wWPoUABipn+OajRqnKhoOdla81H/+vSs50f3uhW0jiOEEHnqWd+PuUOb0jLEk+fbVtU6jiijpAAs5zxHDMfK3Z2sixdJXPKH1nGKlE6n0LO+H9880Vh6/4QQJVqb6t78NPxBHPXWAKiqSnJGtsapRFkiBWA5Z+XsjNeLLwIQ880MzIayuUB5eRnjKIQoO26+SW3G5vP0+moHl+PK5me0KH5SAArcBw/CJiAAU0wscQsWaB2n0BmyjHT/cjuz/w4l02jSOo4QQuRLWqaRJQcjuBxvYMB3uzgbVX5XcRKFR9MC8HyHjpyqWeuWx7XJk7WMVe4otrZ4vzIGgPg5czHGxWmcqHD9svcyp6+l8NPeMKxk2hchRCnjqLfm9+ebU7OCMzEpmQz+fg+nriZrHUuUcpoWgMFLfqfa9r8tj8B5cwFw7tpNy1jlkkv37tjVqYPZYCD2m5laxyk0GdkmvtuWs9rJy+1CsLaSTm8hROnj42LHr889RL2KrsSnZfH47D2cuJKkdSxRiml6NrT28MDa29vySNm6FZvAQByaNdUyVrmk6HT4vPEGAAm//UbWpUvaBioki/65TGxqJhXd7OnXuKLWcYQQosDcHGz5acSDNKjkSoIhmyfm7OV4pBSBomBKTHeImpVF8vIVuPXvf9vVGTIzM0lOTrY8UlJkHERhcnzoQRzbtAajkegvvtQ6zn3L6f3LWVfz5fYh2EjvnxCilHO1t2HhiAdpGOBGoiGboxFSAIqCKTFnxJRNmzClpODar99t20ydOhVXV1fLo3bt2sWYsHzwee01UBRS1q4l/ehRrePcl9/3hxOVnIm/qx0DHpDePyFE2eBiZ8PC4c34+rFGPP5goNZxRClVYgrAxCV/4NS6NTa+PrdtM378eJKSkiyPkydPFmPC8sGuRg1c+/QBSvcScSazahn790K7quitrTROJIQQhcfZzobeDfwtPycasjgmvYFlXkZ24c1kUSIKwOzISNJ278btkYF3bKfX63FxcbE8nJ2diylh+eI9ehSKrS2GfftI3bZN6zgFYqVTmD2kCYObBvBokwCt4wghRJFJMmTz5Ny9PDZ7D/svxWsdRxQys1nlq03neHDKRupMWGeZC/Kz9WdYvO9ygfdbIgrAxKV/YuXpgVPbtlpHEYCNvz/uTz0JQMxnn6GaSufcebX9XfhoQH3sbKT3TwhRdtlYKzjrbUjNNDJk3j/8c1GKwLLk683nWXIggvHda2FjdeMeieq+zvy6L7zA+9W8AFTNZhL/XIpb374o1tZaxxH/8nruOXSurmSeO0/SX39pHSdfSutlayGEKAgHW2vmDWtKqxAvDFkmhs77h90XytZ8ruXZ0kMRTO1fj76NKuaay7aWnwsXolMLvF/NC8C0XbsxXrmKa//+WkcRN7FydcXr+ecBiPnqa8zp6RonunfP/niAcX8cJTKx9GQWQoj7YW9rxZyhTWhdzYv0bBNPL/iHXedjtY4lCsG1pAyCPB1u2a6qKkZzwTs8NC8AnVq1pNbpU+grV9Y6ivgP9ycex9rfD2NUFPELf9I6zj05G5XCxlNR/LY/HPN9/MMQQojSxs7GitlDmtCuhjcZ2WaeXrBPisAyoJqvE/vyGNu5+tg16vi7FHi/mheAouTS6fX4jMlZIi5u9myMCQkaJ7q7+TsvAtCldgUCPG79xiSEEGWZnY0Vs556gI41fXBzsMHfzV7rSOI+je5QjfeWneDbrRcwq7D2xFXG/XGUb7acZ3THagXerxSA4o5cevdGX7Mm5pQU4r6bpXWcO4pPy2LpwUgAhreWHmUhRPmkt7bi2ycf4I8XWxDs5ah1HHGfutSpwNyhTdl5PhYHWyumbzjL+ejUfy/5exd4v3LXhbgjRafD57XXCH/2WeJ/+QX3p57EtlIlrWPl6Ze9YWQazdSr6EqTIHet4wghhGZsrXVUcr9xFWTL6WhMZpVOtX01TCUKqlllD34a8WCh7lN6AMVdObZqiWOL5pCdTUwJXSIuy2jmx91hADzTKvi2ywkKIUR5cywiiecXHuDFnw+w7sQ1reOIfGr9yWYS0rJu2Z6Unk3rTzYXeL9SAIq7UhQF79deAyB55UrST5zQONGtVh27QnRKJj7OenrW87/7C4QQopyo5edMlzq+ZJtUXv75IGuOXdU6ksiHiIR0THlMb5ZlNBOVlFng/colYHFP7OvUwaVXL5JXriTms88InDdP60i5tArx5pVO1fBwtMXWWr7XCCHEddZWOr4Y1BArncKyw1cYuegQX6nQs76f1tHEHWw4GWX5/7/PxuBsZ2P52WRW2XUhlkruBb/JRwpAcc+8XxlDyrp1pO3aTeqOnTi1aql1JAtvZz2vdKqudQwhhCiRrK10TH+0IVaKwtJDkYz+9RAmVeXhBnLFpKR6buF+ABTgtd+P5HrORqejkrs97/SsVeD9SwEo7pltpUq4P/4Y8T/8SPRnn+HYojmKTnrbhBCiNLDSKUx7pAE6ncKSAxG88ush/F3taBLsoXU0kYeLU3sC0OrjzSwf2QoPR9tC3b+cvUW+eL7wAjonJzJPnSJ55Uqt4xAeb+CJOXvYeFNXuRBCiLxZ6RQ+GVCfwU0D6NOwIo0CZcaEkm7HWx0KvfiDAvQAmjMyQFXR2edcd86OjCRl40Zsq4aUqEuComhYu7vj+dxzxEyfTvQXX+DctSs6vV6zPD/susTO83HoFEWmNxBCiHug0ylM6VcPlZyCEHKWFZPZE0ouQ5aRvaHxRCamk20y53ru6ZYFm/c23wVgxEsv49ylM+6DB2NKTubioMEo1taYEhLwHfcW7o89VqAgovTwGPIUCT//jPHKVRJ+/gXPZ57WJEdqppHF+8IBeKaVTPwshBD3Sqe7UeyZzCpvLjlK02B3BjcL1DCVyMvxyCSeXrCPjCwThmwTbvY2xBuysLexwtPJtsAFYL4vAWecPInDAw8AkLxuHdaenoRs3oT/xx+VmvVixf3R2dnhPXoUALGzZmFKStIkx+/7w0nJNFLF25G29zEbuhBClGcrj17hj4MRjFt6jJ/3hmkdR/zH+ytP0qmWD0cmdMHOWsefL7Vk51sdqFvRlXd6FPwmkHwXgOaMDHSOOUvLpO3chXPnzig6HfYNGpB95UqBg4jSxbVvX/TVQjAnJRE3e3axH99kVlmw6xIAz7SsnOvbrBBCiHv3cAN/nvm3F+mdP4/z4+5L2gYSuZy8msyI1lXQ6RR0OoUskwl/N3vGd6/JJ+vOFHi/+S4AbQMDSdm4ieyrV0nbsQPHli0AMMbFo3NyKnAQUbooVlZ4jx0LQPyPC8m+WrwTi24+HU1YnAFXexv6N65YrMcWQoiyRFEU/terFs+1qQLAe8tOMH/nRY1TietsrHTo/h2f6eWkJzIxAwBnOxuu/vv/BZHvMYBeL71E5BtvEPXRRzg+9BAOjRoBkLZzJ3a1Ct4VKUofp3btcGjSBMP+/cR89TX+U6cU27Hn7ggF4LFmgTjYymxGQghxPxRFYXz3mljpFL7deoFJK05iMquMaF1F62i5/Lj7ErO2hRKTmkktPxcmPVyHhgFut22/6uhVPttwhoiEdCp7OjKue03a1/SxPK+qKp9vOMuifeEkp2fTJNidD/rWo7KXo6VNoiGLCctPsOlUNIoC3etWYELvOjjqb5x7Tl1N5r1lxzkSkYSnoy1DWwTzQtuqubIkpWfz6bozrD1xjSRDNhXd7XmvV+1cefJSx9+FoxGJVPZy5MHKHkzfcJaEtCyWHoqkegXnfL6DN+S7B9ClW1eqbd5E5SW/EzDnxqU/x+YP4Tt+XIGDiNJHURR83nwDgKS//iLjTMG7ovNDVVUGNQ2gYYAbQ1sEFcsxhRCirFMUhTe71mBUhxAAPll7hvB4g8apblhx5AofrDzFmE7VWDWqFbX9nBkydy+xqXkvh3YgLJ7Rvx5iUJMAVo9uRZc6vjy3cD9nrqVY2ny3LZT5uy7xYd+6/PVyS+xtrBkyby8Z2SZLmzG/HuZsVCoLhzdj3rCm/HMxnvFLj1meT8nI5qm5/1DRzZ6Vo1oxvkctvth4ll/2Xra0yTKaeWruXiISDHz7RGM2vdaWqf3r4etid9c/9xtda+DtnDPbxutda+Bqb8O7fx0nPi2TKf3q5vt9vE5R1TwWmMsHU2oqhj17sK1cGX3Vqnd/QSGKiIggICCA8PBwKlWqVKzHFjdEvPIqKWvX4timNYHff691HCGEEPdBVVW+3nyeuhVd6FCzaKbXun7+PnnyJBUr3hjGo9fr0d9marE+3+ykQSVXJvfJKXrMZpXmH21iaItgXmoXckv7l385SHqWiXnDmlq29f1mJ7X9XXKmwVFVmk3ZxLOtK/Ncm5z6JTkjmyYfbOTTRxrwcAN/zken0Gn63ywf2ZL6ldwA2HommqcX7GPP+I74utixcE8Yn647w753OlmWIv1ozWnWn7zG5tfaAfDTnjC+/zuUTa+1xcaqZEzBnO8UEa+8SvxPPwM5N4RcGjCQiFfHEtqnL8nr1hd6QFHy+bz6Clhbk/b3dtL27NU6jhBCiPugKAqjO1YrsuLvZrVr18bV1dXymDp1ap7tsoxmjkcm0TLEy7JNp1NoGeLFwbDEPF9zKCwhV3uANtW9ORiWAEB4fDoxKZm52rjY2dAwwM3S5mBYIi521pbiD6BViBc6ReHQ5UTLcZpV9si1Dn2b6l6ExqSRZMgGYOOpKBoHuvHesuM0+WADXT7fxjdbzmMyF7wP7nhkEs8s2Ffg1+e7ADTs349Dk5xpYFI2bERFpcY/e6nwztvEfvddgYOI0ss2KAj3Rx8FIPrTT1HN5ru8ouAW7glj7o6LpGRkF9kxhBBCFI+TJ0+SlJRkeYwfPz7PdgmGLExmFS+n3L2D3k56Ym5zCTgmNRMvJ9v/tLe1XDKOSc2w7ON2+8zZR+7nra10uNnb3LHN9X1eP8bleAOrj1/DZFaZP6wZozpUY/b2UL7efC7P7NdtOxvDh6tO8sna01yOy7kcfz46lWd/3M/DM3Zgvo+LuPlfCSQlBStXVwDSdmzHpUsXdPb2OLVtS9S0TwscRJRuXi+/lDMO8PhxUtauxaVHj0I/Rka2iS83niU2NQtvZ70sYi6EEKWcs7MzLi4uWscocqoKXo62TO1fHyudQr1KrkQlZzDr71Be6VQ9z9cs3neZcUuP4WZvQ1J6Nov3hfNur1pMWHaCXg38Wf9qG0J8ivEmEJsKFUg/fBizwUDq9h04tsxZ/s2UnIzOtvDXqhOlg7WnJx4jhgMQ/fkXqFlZhX6MFUeuEJuahZ+rHd3rVij0/QshhCiZ3B1ssdIpt9zwEZOaeUsP3nXeTnpiU7P+0z7L0lvn7WRn2cft9pmzj9zPG01mEtOz79jm+j6vH8PbWU9lb0fL0nsAVX2ciEnJJMuY91Wz+TsvMa5bTQ6914VvHm9MvCGLhbvDWPdqG6b0q3dfxR8UoAB0HzqEyDfe5Fy79lj7+ODQrBkAhn370VfPu4oV5YPnsGFYeXuRHR5Owq+LC3Xfqqoyb+clAIa2CC4xg2iFEEIUPVtrHXUrurLrfKxlm9mssut8HI2D3PJ8TaMg91ztAXaci6FxkDsAAR72eDvr2XU+zvJ8SkY2h8MTLW0aB7mRnGHkWMSNFa92XYjDrKo0CnSzHOefi/G51ujdcS6WKt6OuDrYANAkyJ1LsQbMN435uxiTho+zPtfYwZuFxRnoUc8PgG51K2CtU3i7Ry38XO3v+F7dq3yfRT0ef5zgRYvw+/ADgn/+CUWXswubgEp4vzKmUEKJ0knn4ID3yyMBiP32W0ypqYW27z2h8Zy6moy9jRWDmwYU2n6FEEKUDiNaVWbRvnCWHIjgfHQK7/x1HEOWkUceyDknjF18mI/Xnra0f6ZlMNvOxjD771DOR6fy+YazHItMYmjzYCDnZpdnWlbm683n2HAyitPXkhn72xF8XfR0qZ1zA0yIjzNtq3szbulRDocnsv9SPBOWn6B3fX/LFC59GvpjY6XjrSVHORuVwoojV5i/8xIjWt2YQ/HJh4JISs9m0ooThMaksvl0FDO3nmdI89tPZZZhNGFva2XJamulw8f57tPG3KsCzaBrX68u9vXqoqoqqqqiKArO7doVWihRerkNHED8Dz+QdfEicXPm4PPKK4Wy37k7cmalH/BARdwcZKiBEEKUN70b+BOflsXnG84Sk5JJLX8XfnimmWWOvMjEdBTlxiXWB4I8+HJwIz5bf4Zp684Q7OXA9081ocZNkye/0LYK6VlGxi89RnJGNk2D3fnh6WbY2VhZ2nw5uCHvLTvBE7P3oFMUutWtwMSH61ied7GzYeHwZry37Di9vt6Bh4MtoztW4/EHAy1t/N3s+eGZZry/8iTdvtxOBRc7nm5Z+ZbJov9r8b5wHP4tAo1mlSUHwnF3zH0OfPrfZfzyq0DzACb+9Rfxc+eRFZazaLRtcDCew5/BtU+fAoUoKJkHsGRK3rCByFGjUezsqLpuHTa+d57l/G4uxabR/rOtqCpseq0tVb1lyUEhhCjN5Px9dy0/2oxyl2XuFQW2v9mhQPvPdw9g3PwFxHz1FR5PPI5948YAGA4c4OrESRgTEvAcNqxAQUTZ4dypE/aNGpF+6BCxM2bg9/7k+9qfCvSo60em0STFnxBCiHJh57iCFXb3Kt89gOc7dsJr1Ejc+vbNtT3xz7+InTGDkE0bCzPfHck3iJLLcPAgYY8/ATodVVYsL5RVYkxmNdcdVEIIIUonOX9rL983gRhjYnBo1OiW7Q6NGmKMiSmUUKL0c2jcGKdOHcFsJvqz6YWyTyn+hBBCiMKR7wLQNiiQ5DVrb9mevGYNtkG3v5tFlD8+Y8eClRWpmzdjOHAg3683msxMW3eai7FpRZBOCCGEKL/yPQbQa+QoIseOxbB/P/aNc3oC0w8eIm3PHip+Xjg9PaJs0FepgtuAAST+9hvRn0wj6NdFue7QupsNJ6P4ZssFfv0nnD1vd5S5/4QQQohCku8zqkvXLgQvXoyVuzupGzeRunETVu7uVP5tMS6dOxdFRlGKeY18GcXenvQjR0jZsCFfr523M2fql8eaBUrxJ4QQQhSigs0DWLcOFad9kmubMS6O2O9m4fXC84USTJQNNj4+eAwbSty33xEz/XOc27dHsbG56+uORiSy71ICNlYKT91hokwhhBCiLEvJyM5z+/XJoW+3ksjdFKgAzIsxJoaYr76SAlDcwnP4cBIX/0bWpUtceecd/D/6yLKCzO3M+3fi5143zbYuhBBClDf1J63nToOn/FztGfBAJV7pWA1dPm6WLLQCUIjbsXJywu/DD4gYOYrk5SvQOThQYcKE244HjErOYOXRqwA8U8AZzoUQQoiy4NOBDfh0/RkGPlCJBpXcADgSkcgfByIY2aEa8WmZfP93KHprHS+3D7nn/UoBKIqFc/v2+H/8MVfeeIPEXxejc3DE543X8ywCf9x9CaNZpWmwO/UquWqQVgghhCgZ/jgYwTs9a9Grvr9lW6favtSo4Mwvey/zy7MP4e9mz4wt5/NVAMrIelFsXHv1tKwKEj9vHrEzZ+bZzklvg6u9jfT+CSGEKPcOhCVQx//WzpA6/q4cvJwAQNNgD64kpudrv/fcAxg19aM7Pm9MiM/XgUX55DZwIGaDgagpU4n9egY6B0c8nx6Wq82L7aoytEUQemurvHcihBBClBP+bvYs3hfOuO41c21fvC8cf1d7ABIMWbja3/0Gy5vdcwGYcerUXds4NGmSr4OL8sljyBDMBgMxX3xJ9Mcfo3NwwH3Qo7naONjK6AQhhBDi7R61ePnng2w9E20ZA3g0MokLMal8+0RjAI5EJOW6RHwv8r0WcEkiawmWXqqqEjN9OnGz54Ci4P/Jx4Q1ak2iIZvW1bzyNWG0EEKI0kXO3/kTHm/g572XuRibCkAVbycebxZIgIdDgfcp3SxCE4qi4D12LOY0Awm//MKVceP5ZNgn7IhTGdu5OqM7VtM6ohBCCFEiBHg43HIJ+H5JASg0oygKvu++g9lg4PjGneyIU1GAPg3z140thBBClGVJ6dkcCU8kLi0Tszn3cwMeKFgPqhSAQlOKToffB+/ziXEOAA9FncT7oi94ynhSIYQQYuPJKF5ZfJi0LCNOeutck0IrilJ6C8DsqCiiP/2MtL//xpyRgW1gIH5TpmBfr67W0UQxScoys84+CLLN9D23jfDnFxO4YD729eppHU0IIYTQ1IerT/FIk0q82bUm9raFNzuGpvMAmpKSCHvscRRrawJmf0+VVSvxeestrFxdtIwlitmif8JJzzZTy9eJB6t4Yk5LI3zEs2ScPat1NCGEEEJT15IyeLpF5UIt/qCAPYCm5GTSjx7DFB+H+p+L0W59+97zfuLmzMHazw//qVMs22zlbqByJdtk5sfdlwAY3qYqAc/O5PLwZ8g4cpTLzwwn+KeF2AYHa5pRCCGE0Eqb6l4cjUwk0LPgd/zmJd8FYMrmLVx54w3MBgM6Jye4eboORclXAZiyeQtOrVoSMeYVDPv2Ye3ri/tjg3F/9NE822dmZpKZmXnj9Skp+Y0vSphrSRk421mTbbKldwM/rKytCPz+e8KGDiPz9GnCnn6G4J8WYlOxotZRhRBCiGLXoaYPU1ef5lxUKjUrOGNtlfvibefavgXab77nAbzQtRuObdvg8+qr6OztC3TQ607XbwCAx7BhuHTrSvqx40RNmUKFiRNx69f3lvYTJ05k0qRJt2yXeYRKN1VViUhIzzWfkTEujrAnnyLr4kVsggIJWrgQGx8fDVMKIYQoLDIP4L2rPH7VbZ9TgNCpPQu033wXgKcbNabK8mXYBgQU6IA3O1WvPvZ16hD86yLLtmsffEjGsWMEL/71lvb/7QGMjIykdu3a8gtURmVfu0bYE0+SHRmJvloIgT/+iLW7u9axhBBC3CcpALWX75tAnFq1JOP48UI5uLW3F7YhVXNt01etQvbVq3m21+v1uLi4WB7Ozs6FkkNoY9vZGAxZxts+b1OhAoEL5mPt40PmufOEj3gWk1z2F0IIIe5bvscAOrVtS9S0aWSev4C+enUUm9y7cO7Q4Z735dCoMVkXL+XalnXpEjb+MhFwWReZmM4zC/bhpLdm82tt8XTS59nONiCAwPnzCHvyKTJOnCD8hRcJnP09OofCHQwrhBBClBTzd17ksWaB2NlYMX/nxTu2fbpl5QIdI98F4NX/vQdA7MyZtz6pKNQ6eeKe9+UxbCiXHnuc2O9m4dK9G+lHj5Hw2+/4Tb51nJ8oW37cfQmTWaW2n8tti7/r9FWrEjh3DmFDh5F+4AARI0dR6btv0dnaFlNaIYQQovjM3XGRvg0rYmdjxdwdty8AFaXgBWC+xwAWtpQtW4iZ/jlZYWHYVKqEx7Cht70L+L9kDEHpZMgy8tCUTSRnGJkzpAmd7vEOJsOhQ1wePgLVYMCpY0cqffE5io1NEacVQghR2OT8rT3NVwJxbt8e5/bttY4hitEfByJIzjAS5OlAh5r3fmevQ6NGBMz8hvDnnid10yaujH8b/48/QrEq3MkxhRBCiLLungrA+B8X4jboUXR6PfE/LrxjW48hTxVKMFE2mc0q83deAuDpFsHodMqdX/Afjg89RMWvviRi5CiSV65EZ29PhcmTUJT87UcIIYQoDUxmlSUHwtl5Po64tEz+s/4Gi557qED7vbcC8IcfcOndK6cA/OGH2zdUFCkAxR1tOxtDaGwaznprBjYp2FRCzu3aUXHaJ0S+9jqJv/+OzsEBn3FvSREohBCizJm04gRLDkTQvqYP1X2dUSicc909FYAhmzbm+f9C5NeRiEQUBQY1DcBJX/ARCC7du2NOz+Dq228T/8MP6Bwd8R49qhCTCiGEENpbceQK3zzemPb5GDJ1LzQfAyjKl1c6VadPw4o4FsKi1m79+2E2GIj64ANiZ85E5+iA5/DhhZBSCCGEKBlsrHQEFfI6wFDAAjD72jVSNm/GePUqalZ2rud8x48rlGCi7Krs5Vho+/J48gnMBgMx06cTPe1TdA4OuD/2WKHtXwghhNDSs62rMH/nJSb3qVOoQ53yXQCm7d5N+EsvY1upEpkXL6KvVo3syEhQVexq1y60YKJsSTJkk5KZTSX3wv8W4/Xcs5jT0oibNYtrkyajc3DAtU+fQj+OEEIIUdz2XYpnd2gcW89GU93HGWur3EXgrKeaFGi/+V4KLnr653g+/TRVVixHZ2tLpa++pNqWzTg0bYpLt64FCiHKvh93X6LNJ1v4bP2ZItm/9ytjcH8q5wakK+PfJnnd+iI5jhBCCFGcXOxt6FqnAg9W9sTd0RZnO5tcj4LKdw9g1oULuH726b+vtkbNyLAMwI946WW5/CZukWk08eOeMMwqVPV2KpJjKIqC7/hxmA1pJP2xlMjXX0dnPwOnNm2K5HhCCCFEUTOazDSv4knr6l74ONsV6r7z3QOoODigZueM+7P29iYrPNzynDExsdCCibJj2eErxKRkUsHFjp71/YrsOIpOh9/kybj06A7Z2USMGk3Cr4tRjcYiO6YQQghRVKytdLzz1zGyjOa7N86nfBeA9g0aYDhwAACnNm2I+vhjYr/7jqtvv4N9g/qFHlCUbqqqMmd7KABPtwzGxirfv3L5olhZ4f/xxzi1b4+amcm1iRO52K8/qTt3FulxhRBCiKLQoJIbJ64kF/p+830J2HfcW5gNBgC8R43EbDCQvHoNtkFB+I57q9ADitJt29kYzkal4qS35rEHA4vlmIqNDZW++pKERb8S8803ZJ47R/jwETi1a4fPm2+ir1KwhbOFEEKI4vZU8yA+XHWKa0kZ1K3oisN/plGr5edSoP3mqwBUTSaM166hr1EDAJ2DA36TJhbowKJ8mP1v79/gpgG43Mdg1fxSbGzwGPIUrg/3JmbmTBJ+WUTq1q2k7tiB+2OP4f3yS1i5uRVbHiGEEKIgRi06BMDEFScs2xRA/fe/oVN7Fmi/iqqqan5ecLp+A6qsXoVtpUoFOmBhioiIICAggPDwcCqVgDwit5iUTDp8uhVDtom/32xPRTd7zbJkhl4keto0UrdsAUDn6or3yy/h/thjKDbFV5gKIYSQ83d+RCQY7vh8QadXy/clYH21amSHh5eIAlCUbN7OenaN78A/F+M1Lf4A9FUqE/DtTNJ27SLqo4/JPHuWqClTSfhlET5vvYlTu3aylrAQQogSpyjmz4UC9ACmbt9O9PTP8R49Crs6ddA55A5m5VQ003zkRb5BiIJQTSYSl/xBzFdfYYqLA8CxRXN83hqHXY3qGqcTQoiyT87f+XcuKoXIxHSyTbnLts61fQu0v3suAGO++QbPp5/mzAM3zTh9c4+JqoKiUOvkiVtfXETkF6jkCo83UMndvkT3qplSU4mbNYv4BT/kTG2k0+E2cCDeY0Zj7empdTwhhCiz5Px97y7HGXhu4X7ORKVYxv5Bzvg/KIYxgKdq16Ha9r/JvHDhju0cmzUrUJCCkF+gkik5I5sWUzcT7OXAvGFNC33yysKWFRFB9KefkbJ2LQA6R0c8X3gejyFD0On1GqcTQoiyR87f9274gn3odAofD6hP6483s2xkSxIM2Xyw6hTv9KhFs8oeBdrvvY8B/LdOLM4CT5ROi/8JJzXTSEa2GS/Hkl9A2VaqRKUvPsew/wmipn5ExokTxHw2ncTFv+Hz+us4d+1SonsyhRBClF0HLyfwy7MP4eFoi05RUBSFpsEevNW1BhOXn2D1mNYF2m/+ZuWVk6C4i2yTmXk7LwLwbOvK6HSl53fGoUkTgn//Db+PpmLt40N2RASRr7xC2FNPkX7suNbxhBBClEMms4qTPqe/zt3RlqjkDAAqutsTGpta4P3m6y7gC92637UIrLF3T4HDiNJv9bGrXE3KwMtJT5+GFbWOk2+KTodb3764dOlC3Nx5xM2dS/r+A1x65BFc+/TBe+yr2PgWbMCtEEIIkV81Kjhz8moyAR4ONAxwY9a2UGytdPzyz2UCPQp+h3C+CkDvkSPROTsX+GCibFNVle//zpn4eViLIOxsrO7yipJL5+CA96iRuD0ykOjp00levoKkZctIXr8ez+HD8Rz+DDp7bae2EUIIUfaN7FCN9KycNe3Hdq7OMz/s45FZu3F3sGXGY40KvN97vwmkVm2q7dheou6OlEGkJcuu87E8PmcvdjY6do/riLujrdaRCk360aNETf2I9EM5M7Jb+/ri89pYXHr1QtEV7frGQghR1sj5+/4kGrJwtbe5r/Hp937mkvF/4i5WHL0CwKNNAspU8QdgX78+Qb/8TMXPp2Pj748xKoorb77FpUGDMRw8qHU8IYQQZdyl2DS2nY0hI9uEm8P9n2PzfRewELfzYd96dKjpS80KZXOYgKIouHTvjlOHDsQv+IG4WbPIOHaMsMefwLl7N3xeex3bSqVv3KMQQoiSKyEti5d/Ocju0DgUYOvr7Qn0dODNJUdxtbfh3V61C7Tfe+4BrHXqZIm6/CtKHp1OoXNtXwLuY1BqaaDT6/F6/jmqrluL2yMDQVFIWbOW0B49iJo6leyoaK0jCiGEKCPeX3kSaysdu8Z1wP6msfW9Gviz7WxMgfcrg5fEfcuZ88+kdYxiZ+3tjd/771P5z6U4PPQQalYW8T/8yIVOnbg6aRLZkZFaRxRCCFHK/X0ulnHdauLnmvvGw8qejkQmphd4v1IAivv23dYLtPxoM38ciNA6iibsatYkcP48AubMwf6BB1Czs0lc9Cvnu3bjyjvvkBUWpnVEIYQQpVR6lhF721tn1UhMz8LWuuBlnBSA4r4Ysows3BNGXFoWjvrSO+3L/VIUBadWLQn6aSGBP/yAQ/OHwGgk6Y+lXOjeg8g337zrMopCCCHEfzWt7MHSgzc6WBQFzGaVWdtCaV6l4EPz8jUPoBD/teRABEnp2QR5OtC5dgWt42hOURQcH2yG44PNMBw6ROx335G27W+Sl68gecVKnLt2xeuF57GrWVPrqEIIIUqB8d1r8cScPRyNSCLbpDJ1zSnORqWSaMjmjxebF3i/0gMoCsxkVpmzPWfZtxGtKmNVipZ9Kw4OjRoROGsWwUuW4NSpI6gqKWvXcrFvP8Jfepn0Y8e0jiiEEKKEq1HBmc2vt6NpsDuda/tiyDLRrU4FVo9uRZCnY4H3Kz2AosDWn7jG5XgD7g42DHwgQOs4JZZ93ToEzJhBxpmzxM36juQ1a0ndvJnUzZtxbNUKr5dexKFxY61jCiGEKKFc7GwY2aFarm1Xk9IZv/QoU/vXL9A+pQdQFIiqqsz6d9m3Jx8KynOAqsjNrkZ1Kk6fTpVVq3Dt0wesrEjbsYOwx58gbMhQ0vbs4R4X5hFCCFHOJaRls3hfeIFfLwWgKJBz0akcDk/E1krHkObBWscpVfRVKuP/8UdUXbsGt0ceARsbDP/8w+VhTxP2+BOk/v23FIJCCCGKlFwCFgVS3deZ9a+24WhEEt7Oeq3jlEq2AQH4vT8ZrxdfIG7uPBJ//530Q4cIf+557OrUwevFF3Dq0EHWGhZCiH/9uPsSs7aFEpOaSS0/FyY9XIeGAW63bb/q6FU+23CGiIR0Kns6Mq57TdrX9LE8r6oqn284y6J94SSnZ9Mk2J0P+tajsteNsXWJhiwmLD/BplPRKAp0r1uBCb3r4Ki/UUKduprMe8uOcyQiCU9HW4a2COaFtlXzzLT8yBVGLzpE59q+zB7S5P7flAKSM4sosOq+zgx8QBbxvl82/v5U+N+7VN24AY9hw1Ds7ck4cYKIkaO42LcfyWvWoJrK30TbQghxsxVHrvDBylOM6VSNVaNaUdvPmSFz9xKbmpln+wNh8Yz+9RCDmgSwenQrutTx5bmF+zlzLcXS5rttoczfdYkP+9blr5dbYm9jzZB5e3MtbjDm18OcjUpl4fBmzBvWlH8uxjN+6Y2b+FIysnlq7j9UdLNn5ahWjO9Riy82nuWXvZdvyRQeb2DKqlM0C/YoxHemYKQHUORbWqYx1zcfUThsfHzwHfcWns89S/yCH0j4+Wcyz54l8tWx2Fapgtfzz+HSsyeKtbz3QojyZ86OiwxuFsCjTXJuOvywbz02n47mt/3hvNQu5Jb283Zeom11b57/tyfutS412H4ulh92X2JKv3qoqsq8nRcZ1SGELnVypjGbPqgBTT7YyPqTUTzcwJ/z0SlsOxvD8pEtqV/JDYCJD9fh6QX7eKdnLXxd7Pjr8BWyTWY+GdgAW2sd1X2dOXklmTk7Qnn8wUBLHpNZ5ZXFh3m1czX+uZhAckb2Hf+8zy/cf8fnk9ON9/ze5UV6AEW+xKVm8tCUTYxdfJj0LOmVKgrWHh74jH2VkE0b8Ro5Ep2LC1mhoVx5axwXuvcg4fffUbOytI4phBD3LSUlheTkZMsjMzPv3rwso5njkUm0DPGybNPpFFqGeHEwLDHP1xwKS8jVHqBNdW8OhiUAEB6fTkxKZq42LnY2NAxws7Q5GJaIi521pfgDaBXihU5ROHQ50XKcZpU9cq3K0aa6F6ExaSQZbhR5X246h6ejLYOa3igK78TZzuaOj4ru9vRvXPCrcNKVIPLlpz2XSck0ci46FTsb+f5QlKzc3PAe+TIew4aS8Msi4ufPJzs8nGv/e4/Ymd/iOWI4bgMHotPLGEwhROlUu3btXD9PmDCBiRMn3tIuwZCFyazi5ZT7887bSc+FmLQ89x2TmomXk+1/2ttaLhnHpGZY9vHffcZY2mTeckxrKx1u9ja52lRyd7hlH9eP4epgw75L8fy2L5zVY1rnmTUvnz7S4J7bFoQUgOKeZWSb+HH3JQCebVMFRZGJn4uDlZMTXs89i8eTT5Cw+Dfi5s3FePUqUe9/QNz3s/F68QXc+vdHsbW9+86EEKIEOXnyJBUrVrT8rC+DX2hTM428uvgwUwfUw8Ox5HxOSwEo7tmfhyKJS8uiops9PerKsm/FTefggOfTw3B//DESlywhbvYcjNeucW3iJOLmzMVr5Mu49u6NYiVzMgohSgdnZ2dcXFzu2s7dwRYrnXLLDR8xqZm39OBd5+2kJzY16z/tsyw9et5OdpZ9+LjY5dpnbT+Xm/aR+5hGk5nE9GzLcfNqc7130NvJjrC4NCIS0hnxw40xfeZ/p/qq+vZqNr/W9r5W9CgouYYn7onZrDJ7e87Ez8+0qoy1lfzqaEWn1+PxxBNUXbcW37ffxsrTk+yICK6OG0/ow31IXrsO1WzWOqYQQhQaW2sddSu6sut8rGWb2ayy63wcjYPc8nxNoyD3XO0BdpyLoXGQOwABHvZ4O+vZdT7O8nxKRjaHwxMtbRoHuZGcYeRYRJKlza4LcZhVlUaBbpbj/HMxnmyT+abjxFLF2xFXBxuqejux7pU2rB7d2vLoVMuX5lU8WT26NX6u9vf13hSUnMXFPdlyJprQmDSc7awZ1FSWfSsJdHo9HkOeImTDerzHjkXn6krWhQtEvvIKFwcOJHXbNplQWghRZoxoVZlF+8JZciCC89EpvPPXcQxZRh75dynSsYsP8/Ha05b2z7QMZtvZGGb/Hcr56FQ+33CWY5FJDP138QJFUXimZWW+3nyODSejOH0tmbG/HcHXRU+X2r4AhPg407a6N+OWHuVweCL7L8UzYfkJetf3x/ffXsM+Df2xsdLx1pKjnI1KYcWRK8zfeYkRraoAYGdjRY0KzrkeLnY2OOqtqVHBOdfNI8VJ00vAMV/PIPabb3Jts61cmaprVmuUSNzOj7vDAHj8wUCcZAqYEkXn4IDXc8/iPngQ8QsWEL/gBzJPniL8+Rewb9QI71dewfHBZlrHFEKI+9K7gT/xaVl8vuEsMSmZ1PJ34YdnmlkWI4hMTM81Nv2BIA++HNyIz9afYdq6MwR7OfD9U02oUcHZ0uaFtlVIzzIyfukxkjOyaRrszg9PN8PO5sZQmi8HN+S9ZSd4YvYedIpCt7oVmPhwHcvzLnY2LBzejPeWHafX1zvwcLBldMdquaaAKYkUVcMugpivZ5Cyfh2B8+bd2GhtjbW7+z29PiIigoCAAMLDw6lUSSYkLkpJhmx+2htG/8YVNeuuFvfGGB9P3Jy5JPz8M+q/Uyo4tmiO95gx2Dco2rvKhBDiXsj5W3vaXwK2ssba2/vG4x6LP1G8XB1seLl9iBR/pYC1hwe+b75B1fXrcX/8MbCxIW3Xbi4NGkz4iy+RceaM1hGFEEJoTPMCMCssjHOt23C+U2ciX3+D7CtXbts2MzMz14SRKSkpt20rCkeWUW4mKK1sfH2o8N57VF2zBtd+/UCnI3XLFi726Uvk2LFkhl7UOqIQQgiNaHoJOPXvvzEbDNhWrowxOobYb74hOzqKKstXYOV06y3REydOZNKkSbdsly7kojN5xUkOhScwrltNHqziqXUccR8yQ0OJ+fprUtaszdmg0+Haty/eL7+EzU3zcAkhRFGTS8Da07QA/C9TcjLnO3TEd9xbuA0ceMvzmZmZuZaJiYyMpHbt2vILVESS0rNpMXUTaVkmfnimGW2re2sdSRSCjFOniPnyK1K3bs3ZYGOD+yOP4PnC89j4+GiaTQhRPkgBqD3NLwHfzMrFBdvgYLLCLuf5vF6vx8XFxfJwdnbOs50oHIv+uUxalokavs60qeZ19xeIUsGuVi0CvvuW4F8X4dD8IcjOJuGXX7jQpStR06ZhTEjQOqIQQogiVqIKQHNaGlnh4Vh7S0+T1rKMZubvzBkjJsu+lU32DRsSNH8+gQsWYN+wIWpGBvFz53GhU2divp6BScbYCiFEmaVpARj18Sek/fMPWRGRGA4eImLUKBSdDpdePbWMJYAVR64QlZyJj7Oehxv4ax1HFCHHhx4kaNEvVPruW/S1amFOSyP2m2+40KkzsbNnYzYYtI4ohBCikGlaABqjrnHltdcJ7d6dyFdfxcrNjeDFv2Lt4aFlrHJPVW8s+zasZbBms5SL4qMoCs7t2lH5jyVU/OJzbKtUwZSURMxn0znfpSvxC3/CnJV19x0JIYQoFUrUTSD5JYNIi8au87E8PmcvDrZW7B7XEVcHG60jiWKmmkwkrVhB7IxvyI6IAMDa3w/vl17CtW9fFGtZDUYIUXBy/taedO2IWzxYxZOZTzTmza41pPgrpxQrK9z69qXq6lVUmDgBax8fjFeucvXd/3GhZ0+SVqxANZm0jimEEKKApAdQCHFX5owMEhb9Stz332P69y5h25CqeI8ajXPnTig6+S4phLh3cv7Wnnxqi1zM5lL7fUAUIZ2dHZ5PDyNk4wa8X3kFnYsLWecvEDlmDBcHDiRl61ZK8XdJIYQod6QAFBZRyRm0/mQL32w5j0kKQZEHnaMjXi88T8jGDXi99BI6BwcyT54i4oUXCRv8GGm7dkkhKIQQpYAUgMJiwa5LRCams+1MDFY6mfdP3J6Viwveo0dRddNGPEcMR7GzI/3IES4/M5zLQ4ZiOHBA64hCCCHuQApAAUBqppGf94QBORM/C3EvrN3d8Xn9dUI2rMf9qadQbGww7NtH2BNPcnnEs6QfO6Z1RCGEEHmQAlAA8Nu+cJIzjFTxcqRjTVkPVuSPtbc3Fd55m6rr1+H26KNgbU3ajh1ceuRRwl8eScaZM1pHFEIIcRMpAAVGk5m5O3KWfRveujI6ufwrCsjGzw+/yZOoumY1rn37gk5H6qZNXOzTl8ixY8kMDdU6ohBCCKQAFMCa49eITEzHw9GWAY3ldnxx/2wDAvD/aCpVVq7ApUd3AJJXryG0V2+uvDWOrPBwjRMKIUT5JgWgYM6/y74NaR6EnY2VxmlEWaKvUoWK06dTedlfOHXsCGYzScuWcaF7D66+N4Hsq1e1jiiEEOWSFICCKf3rMfCBSjz1UJDWUUQZZVejBgHfzCD4999wbN0ajEYSf/uNC126cu3DKRhjYrSOKIQQ5YqsBCKEKHaGAweI+eJLDPv2AaDY2eHx5BN4DB+Otbu7xumEEEVNzt/akx7AcqwU1/6ilHN44AECf/yBwPnzsG/QADUjg7g5c7nQqTMxX32NKTlZ64hCCFGmSQFYjk1cfoI3lxwhLC5N6yiiHFIUBcfmzQn6dRGVvvsWfe1amNPSiJ05k/OduxD73SzMafK7KYQQRUEKwHIqJiWTRfvC+W1/BNEpmVrHEeWYoig4t2tH5SVLqPjVl9iGVMWclETMF19wvlNnYr+bhSklReuYQghRpkgBWE4t3BNGltFMgwA3mgTJmCuhPUWnw6VLF6osW4b/tGnYBAViSkjIKQQ7dCT6yy8xJiRoHVMIIcoEKQDLoeSMbBbuvgTAc62roCgy8bMoORQrK1x796LqqlX4T/skp0cwJYW4b7/jfMdORH38CdnR0VrHFEKIUk0KwHJo1rYLJBiyqeLtSNc6vlrHESJPirU1rr17U2X5cip+9SV2tWujGgzEz5/PhU6duTppElkRkVrHFEKIUkkKwHLmWlKGZdm3t7rVxNpKfgVEyXb90nDwH0sI+H4W9o0bo2ZlkbjoVy5068aV8W+TGXpR65hCCFGqyNm/nPlu2wUyss08EOROl9rS+ydKD0VRcGrThqCffyLwxx9wbNEcjEaS/vyT0J49iXj1VTLOnNE6phBClArWWgcQxeu1LtVx0lvTvqa3jP0TpZKiKDg2a4Zjs2akHz1K7HezSN28mZQ1a0lZsxan9u3xeuF57Bs00DqqEEKUWLISiBCi1Ms4c4a4WbNIXrMW/v1Ic2zRHM/nX8ChWVP5siNECSPnb+3JJeByIiEtS1b+EGWWXY0aVJw+nSqrVuHarx9YW5O2azeXhw4l7PEnSN22TX7/hRDiJlIAlgOqqvLMD/vo/+0uzkfLhLqi7NJXqYz/1CmErFuL++OPodjakn7oEOHPv8DFAQNIXrce1WzWOqYQQmhOCsByYN2Jaxy6nMjpqym42NloHUeIImdTsSIV3nuPqhs34PH00yj29mSePEXkmDGE9n6YpOXLUY1GrWMKIYRmpAAs47JNZj5Zm3Nn5IjWlfFxsdM4kRDFx8bHB9+33iRk8yY8X3wBnbMzWRcucOXNt7jQvQcJi3/DnJWldUwhhCh2UgCWcYv3hRMam4aHoy3PtamidRwhNGHt7o7PmDGEbN6E96uvYuXuTnZ4ONcmTOBC5y7E//gj5vR0rWMKIUSxkQKwDEvLNPLFxnMAjO4QgrNc/hXlnJWzM17PP0fIpo34jh+HtY8PxqgooqZM5XzHTsTO+h5TioyTFUKUfVIAlmGzt4cSm5pJkKcDjz8YpHUcIUoMnYMDHkOHUnXjBipMnIhNpUqY4uOJ+fxzzrfvQPT0zzHGxmodUwghiowUgGWUqqrsPJ9zAnu9Sw1sreWvWoj/0tna4j54EFXXrsH/44+wrVoVc2oqcd9/z/mOnbg2ebKsNyyEKJNkIugyzGxW2Xgqik61fNHpZCJcIe5GNZtJ3byZ2O9nk3H0aM5GKytcevbAc8QI7KpX1zagEGWEnL+1J91CZZhOp9ClTgUp/oS4R4pOh3OnTgQv/pXABQtwbNECTCaSl6/g4sN9CH/xJQyHDmkdUwgh7psUgGXQ2uNXSc8yaR1DiFJLURQcH3qQwHlzCf79d5y7dgVFIXXLFsIee5ywp4aQun27rC4ihCi1pAAsYw5dTuCFnw7S8bOtpGXKRLdC3C/7enWp9OUXOcvMDegPNjYY9u0j/NnnclYXWbMG1SRfuIQQpYsUgGWIqqpMXXMagBYhXjjqrTVOJETZoa9SGf8PPyRkw3o8hg69sbrIq2O50KMHCb/JpNJCiNJDCsAyZPPpaP65GI/eWsfYzjJYXYiiYFOhAr7jxxGyeRNeL7+Mlasr2WGXufbeBC506kzcvPmYUtO0jimEEHckBWAZYTSZ+ejf3r+nW1bG381e40RClG3W7u54jxpJyOZN+Ix7C2tfX4zR0UR/8gnnO3Yk5quvMCYkaB1TCCHyJAVgGfHHwQjORafi5mDDi+2qah1HiHJD5+iI57BhVN2wHr8PP8A2OBhzUhKxM7/lfPsOXPtwCtlXr2odUwghcpECsAxIzzIxfcNZAEa2D8HVXpZ8E6K46WxtcRswgCqrVlLxiy+wq10bNSODhIULOd+5C1fGv01maKjWMYUQApACsExIzTTSONCdSu72PNVclnwTQkuKlRUu3boS/McSAubOweHBB8FoJOnPPwnt2YuIUaNJP3ZM65hCiHJOVgIpQ5IzsnGxk94/IUqa9CNHiJ09m9SNmyzbHJo/hNdzz+Hw0EMoikzWLsoXOX9rT3oAyxAp/oQomewbNCBgxgyqrFyBa58+YG2NYfceLj/9DBf79Sfxjz8wZ2RoHVMIUY6UmAIw9vvZnKpZi2tTpmgdpdQIjzfw5pIjRCamax1FCHEP9CEh+H/8ESHr1uL+5JModnZknj7N1Xfe5Xy79kR/Nl1uGBFCFIsSUQCmHztG4uLF6GvU0DpKqfLp+jP8tj+Cd/+U8URClCY2FStS4d13qLZ1Cz5vvIGNvz+mxETiZs/mfKfORIx5BcP+/bLUnBCiyGheAJrT0rjy+hv4vT8ZKxeXO7bNzMwkOTnZ8khJSSmmlCXP8cgklh2+AsBrXaRwFqI0snJzw3P4M1TdsJ5K38zA4aGHwGQiZd06wp58iov9B5D4x1LMmZlaRxVClDGaF4DXJr+PU7u2OLZocde2U6dOxdXV1fKoXbt2MSQsma5P+tynoT91K7pqnEYIcT8UKyucO3YkaMF8Ki9bhtujj+ZcHj51iqvvvJNzeXj653J5WAhRaDQtAJNWrSLj5Em8x469p/bjx48nKSnJ8jh58mQRJyyZ/j4bw47zsdha6Xhdev+EKFPsalTHb/Kkfy8Pv461vx+mhATivv8+5/LwK69iOHBALg8LIe6LZgVg9tWrRE2Ziv+n09Dp9ff0Gr1ej4uLi+Xh7OxcxClLHrNZtfT+PflQEAEeDhonEkIUhZzLw8MJWb+eil9/lTOfoMlEytq1hD3xJBcHDCBx6Z9yeVgIUSCazQOYsnEjESNHgZXVjY0mEygK6HTUPHoE5ebn8lAe5xFadjiSMb8exllvzbY32+PhaKt1JCFEMck4c5aEn34iafly1H8LPyt3d9wGPYr7Y49h4+urcUIh7k15PH+XNJoVgKbUNLKvRObadvXtd7CtUhnPESOwq179rvsoj79AyRnZzNp2AXcHW0a0rqJ1HCGEBowJCST98Qfxv/yC8cq/4wKtrHDp2gX3J5/EvlEjmVxalGjl8fxd0pSolUDCnhqCvlZNKrz99j21l18gIUR5phqNpGzeTMLCnzDs22fZble7Nu5PPYVLj+73PMRGiOIk52/taX4XsLg3WUazDPoWQuSiWFvj0qULQQt/pPKyv3B7ZCCKXk/GyZNcHT+e8+07EP3ll2RHRWkdVQhRwpSoHsD8Kk/fIKauOcW+i/FM6F2HBgFuWscRQpRQxoQEEpcsIeGXRRivTxvzb6GYc3m4oVweFporT+fvkspa6wDi7q4kpjN/5yWyjGZiU+WOPyHE7Vm7u+P17LN4Pv00KZs2k7BwIYb9+0levZrk1avR166F++DBuPbqhc5BZhEQpcuPuy8xa1soMamZ1PJzYdLDdWh4h06RVUev8tmGM0QkpFPZ05Fx3WvSvqaP5XlVVfl8w1kW7QsnOT2bJsHufNC3HpW9HC1tEg1ZTFh+gk2nolEU6F63AhN618FRf6OEOnU1mfeWHedIRBKejrYMbRHMC22rWp5f9M9llh6M4My1nAUs6lVy5Y2uNe+YvajJJeBSYPqGs2QZzTSr7EGHm35xhRDidhRra1y6diHop4VU/utPXAcOQNHryTx5imvvTeBcm7Zce/8DMs+d0zqqEPdkxZErfLDyFGM6VWPVqFbU9nNmyNy9t+0YORAWz+hfDzGoSQCrR7eiSx1fnlu431KEAXy3LZT5uy7xYd+6/PVyS+xtrBkyby8Z2SZLmzG/HuZsVCoLhzdj3rCm/HMxnvFLbyzBmpKRzVNz/6Gimz0rR7VifI9afLHxLL/svWxpsyc0jocb+LPouYdY+lJL/FzteWruXq4lZRTBO3VvpAAs4U5fS+aPgxEAjO9eUy7dCCHyza5mTfw/+IBq27bi89Zb2AYFYU5NJeHnnwnt/TBhTz5F0spVmLOytI4qxG3N2XGRwc0CeLRJANV8nfmwbz3sba3+3969x0VV5/8Df80wzADDHeQyGjdRUQTCVEJQU7ygrkB5/5ph1ra2WFqbuftzXW1bU2vLylxKM2u7aOYqqKWIoCTeFVHMK94VBbwAMyC3mc/vD3ISNS2dwwzM6/l4zOMh55w5r89B5pz3fM45n4MVe8/fdfnPtp1B7/at8KfebRHs5YS/DOiAUI0LvthxBkBD799n207jpb7BGBDqg46+znhvVASKK2qw8XDDdbOFJVrkHC/FvGFhiPRzQ7cAd8xKCMXag0Uormgo3tLyi1CnN+Dt4RFo7+2EhAgNxvcIxKe5p4xt+WB0JMZFByBU44JgL0fMGxYOIYBthVek/aXdAwtACzd3/VEIAQwO80Gkn5u5m0NEzZiNqys8nh2PoPU/wO+zJXDq3x+wsUHV3r0oeu21hkfOvfseai9cvP/KiExAq9WioqLC+Kr5lYHNa+sNOHSxHDHBnsZpcrkMMcGeyDtbdtf37D97vdHyANCrfSvknb0OADh/7QZKtTWNlnG2s8Wjj7gal8k7WwZnOwXC27gal4kN9oRcJsP+c2XGnO6B7lAq5LfkeOJUaSXKq+ru2rYbdXrU6Q1wdbC9+y+mCbAAtGDbT17BlmOlUMhlmDowxNzNIaIWQiaXQ92jB9os+BDB2VnwnDQJCi8v6K9dw9XFi3Gyf3+c+9OfoN28GUKvv/8KiR5Qp06d4OLiYnzNmTPnrstdr6qF3iDg6dh4WKNWjiqU/sop4FJdDTwdlbctrzSeMi7VVRvX8WvrbFhH4/kKGzlc7W3vuczNdd7MuN3c9Ufg7Wx3R4HalHgTiAVbubfh1O//Rfk1uiCViMhUbL290WpSCjwnNhR8ZcuWo3L7dlTm/IjKnB9hq9HAdeRIuA4fBoWn+Q5W1DIdPnwYrVu3Nv6ssoJxK/+zpRBrD1zC8hceh53tvZ94JiUWgBbsnRER6BHsid7tW5m7KUTUwskUCjj37w/n/v1Re+YMrn+7AuWrVqGuqAil77+P0oUL4dy/H1xHj4ZDt268HplMwsnJCc7Ozvddzs1BCRu57I4bPkp1NXf04N3UylGFK7ra25avNfbWtXK0M67Dy9mu0To7+Trfso7GmfV6A8pu1Blz77bMzd7Bmxk3LfrxJFK3nMTXz0eho+/9t1tKPAVswWzkMgx/rA1aObX8b0REZDmUAQHwnvY6gnO2wHfuHNhHRAB1daj4YT3OPZOMU0OH4tqXX0FfUWHuppKVUCrk6NzaBdtvuWnCYBDYXngVXfxd7/qeSH+3RssDQO6JUnTxb7ie/hF3e7RyUmF74VXjfG11HfLPlxmX6eLviorqehRcKDcus/3kVRiEQKSfqzFn9+lrqNMbbsm5gqBWarjcco3fxzknsSCrEF9M6N7omkJzYQFogQoulDe6BZ2IyBzkdnZwTUpCwLfLEbh6FVxHjoTMwQG1hSdRPHs2TvR+AkV//ztuHPrJ3E0lK/B8bCCW7TmPlfsuoLBEi+lph1BVW48Rjz0CAHj123zM23DUuPyEmADkHC/F4h9PobBEh/mZx1FwsRzJ0QEAAJlMhgkxgViQfQKZh4tx9HIFXl1xAN7OKgzo5A0ACPZyQu/2rfDXVQeRf74Me89cw8w1P2FouAbeP/caJj6qga2NHNNWHsTxYi3WHijC0m1n8HxskLEtqVtO4r2Nx/H28HC0cbNHibYaJdpqVNbUN9Fv7058EoiF0VbXofc7W6C0keOr56MQ7OVo7iYRERnpdTqUp6ejbPly1JwoNE63CwuD2+jRDc8ftrc3YwupOXjQ4/cX289g0Y+nUKqtQUeNM2YN7WQcIWPUJzvQxs0B746MMC7//cFLeHdjw0DQAZ4O+NugjncdCPqb3edRUV2HbgFueDOxM4Ja/XLsLauqxT/Sf0LWkWLIZTLEd/bBrIRfHwja3aFhIOgXn/hlIOiYudm4WHbjju2ZHNcOr/Rv/5u335RYAFqYdzcew4LsQgR5qpHxSi/Y2rCTlogsjxACN/btw/Xl30KbkQFR1zDchdzZGa5PJsF11GioggLN3EqyVC3x+N3csLqwICUV1fh062kAwOvxHVj8EZHFkslkcOjaFa3//Q6Ct2xGq7+8Cts2bWCoqMC1L/6LU4MH4+z4Z1Hxww8w/MrYbkRkPrwL2ILM33QCN+r06OLnioGhPuZuDhHRb6Lw8Gh4/vBzz6EyNxfXly2HLicHVTt3omrnTsidnOA8aBBckhJhHxnJO4iJLAALQAtRWKLFt3sanhv4t8EduYMkomZHJpfDsVcvOPbqhbqiIlz/7juUp6ejvugSylasQNmKFbD194NLYiJcEhKhbNP6/islIknwHKOFmLfhGAwC6NfRG90C3M3dHCKih2Kr0cBr8mQEb9oEv88/h0tSEmQODqg7ew5XPlyAk/364ey4Z1D2v1XQ6yrN3Vwiq8MC0AIIIeDpqIRcBkyL72Du5hARmYxMLof68Sho5s5B+60/QjNvLhyiHwdkMlTt2YNL06fjRGwsLk59Hbpt2/joOaImwruALYQQAvvPl6HLz7ezExG1ZHVFRShfsxblaWmoPXPGOF3h7Q2XhKFwSUqCqm3bX18BNWst6fjdXLEANKOyqlo4qhRQ8G5fIrJSQghUHzyIsrQ0VPywHobyX564YBcWBpfERDgPGQyFG78ctyTN/fjdErAANJPqOj1GfbIDLg5KLBgTCRd72/u/iYioBTPU1kK3eQvK09Kg27oVqP/5KQm2tnB6ojdcEhPh2KsXZEqleRtKD605H79bCt4FbAZCCPxtVQEOXCiHq4MtyqpqWQASkdWTK5VwHjgAzgMHoP7qVVR8/z3K0tJQc/gItJmboM3cBBs3NzgPGQKXxETYdQ7liAlED4g9gGbwcc5JzF1/FDZyGb6c0B09gj3N3SQiIotVfew4ytPTUb52DfSlV4zTlcFt4ZqUBOehCbD19rrHGsjSNNfjd0vCArCJZR8txnNf7IUQwD8TQ/HMzw+lJiKiexP19ajcvh3laenQZmVB3HzCiFwOdXQ0XJKS4NQvjs8ibgaa4/G7peEp4CZUWKLFy8vyIQTwf1F+GPe4v7mbRETUbMgUCuNA0/qKClRs2IDytHTcyMtD5bZtqNy2DXK1Gk7xA+GSkAiHbl0hk/MmO6K7YQ9gEzEYBIYsyMWRSxXoHuiOr56LglLBHRMR0cOqPXcO5WnpKE9PR93Fi8bpCo0vXBIS4JKQCFVQoBlbSLdrTsfvlooFYBP6qagc/1x7GP8Z2wUejipzN4eIqEURBgNu7NuH8jVrULF+Aww6nXGeXUR4w5AygwZxSBkL0NyO3y0RC0AiImpxDNXV0GVnoyw9HZW524CbTxixtYVj714NQ8r07g05h5QxCx6/zY/XAEps9f4L8PdQ8wkfRERNSG5nB+fBg+E8eDDqr1xpGFImPR01h49AtykLuk1ZsHFxgfOQwXBJSIBdRASHlCGrwh5ACe0+fQ1jP90JGWRIS4lBJ42zuZtERGTVqo8fR8WaNShfsxb1JSXG6Up/f7gkJcJ5aAKUbVqbsYXWwdKP39aAdyFI5Py1Kkz8ah/q9AL9Q73R0dfJ3E0iIrJ6du3bw+u11xC8ORuPLPkUzglDIbO3R+3Zsyj94EOc7NcPZ58eh7KVK6HXas3dXCLJsAdQApU19RiWuh1HL2sRqnHGyok9YK+0MXeziIjoLvS6Smg3ZaI8PR1VO3cBPx8WZSoVnOLi4JKYAHVMDGQKXjVlKpZ6/LYm/Gs2MYNB4NUV+Th6WQtPRxUWP9OVxR8RkQWzcVTDNSkJrklJqLt0CeVr16E8PR21J0+i4ocfUPHDD7Dx9ITLkCFwSUqEKiSE1wtSs8ceQBN7b+MxfJhdCKWNHMteeByP+fPmDyKi5kYIgeqfDqM8PR0V69ZBf/26cZ6qffuGIWX+8Ac+gu4BWeLx29rwGkATMhgEjhc3jDv11lNhLP6IiJopmUwG+86h8Jn+/9Duxxy0+c9/4BQfD5mtLWqOH0fJO++gsE8fnJvwHK4vW4a64mJzN5nod2EPoIkZDAI/nijFEx34rZCIqKXRl5ejYkMGytMbHkF3K7vOneEU1xeOfeOgat+Op4nvwRKP39aGBaAJ6GrqoVba8MNORGRFas+dQ0VGBnRZ2bhx4IDx5hEAsH3kETj17QvHuL5w6NKFN5DcxlKO39aMBeBDqqnXY8yinWjj5oC3h4fDzpY3fBARWZv6K1eg3bwZuqxsVG7fDlFba5xn4+ICxyeegGNcXzjGxECuVpuxpZbBEo7f1o5fSR6CEALTVx9C3rkyFJbocLm8GgGe/GATEVkbhacn3EaMgNuIETBUVUG3bRt0WdnQbd4MfXk5ytPTUZ6eDplSCXV0NBzj+sKpTx8oWrUyd9PJSrEAfAhLck9j5b4LkMuAj/6vC4s/IiKC3MEBzv37w7l/f4j6elTl5UGXlQ1tdjbqzp+HLicHupwcXJbNgn14OBzj4uAU1xfKoCBeSkRNhqeAH1DO8VI8u3Q3DAKY8YdOeC42sEnziYioeRFCoObECeiys6HNykZ1QUGj+Up/f2MxaP/oo5DZtNxLingK2PxYAD6Ak6U6JC3cBm11PUZ2bYN5w8L5rY2IiH6XuuJi6DZvhjYrG1U7d0LU1Rnn2bi7w/GJJ+DULw7q6GjI7e3N2FLTYwFofiwAfye9QWDwB1txrFiLx/zd8M0fo6BStNxvaUREJD29TofKrVuhzcqGLicHhlueQyyzs4M6JqbhruI+T0Dh7m6+hpoIC0DzYwH4AHaeuop/fX8YS8d3RysnVZPlEhFRyyfq6lC1dy+0WdnQZmehvujSLzNlMtiFh8Exticce8bCLiysWZ4qZgFofmYtAK8vW4bry5aj7uJFAIAqOBieKX+GY69ev+n95vwDEkLwtC8REUlKCIGao0eNxWDN4SON5stdXOAY0wPq2J5Qx8bA1qt5PISABaD5mbUA1GZvhsxGDqW/P4QQKE9Lx9XPPkPQqv9B1a7dfd/flH9APxRcQjsvR7TzdpI0h4iI6NfUXb6Mym3boNuai8rt22GoqGg0XxUSAseesVDH9oRD5KOQKZVmaum9sQA0P4s7BXws6nF4T30NrsOH3zGvpqYGNTU1xp8vXryITp06Sf4HtO/sNYxZtAtKhRxpKTEI9nKULIuIiOi3EPX1uHGwAJW5W6HbmovqQ4caPY1E7uAAh+jonwvCWCgtqNBiAWh+FjMOoNDrUbFhA0RVFewfffSuy8yZMwdvvPFGk7arqOwG/vRlHmr1BvQN8UIQx/ojIiILIFMo4NAlEg5dItHq5ZdRf+0aKrdtbygIc7dBf/UqdFlZ0GVlAQCUgYFQ94yFY8+ecOjWDXI7OzNvAZmT2XsAq48dx5kxYyBqaiB3cEDrf78Dx96977psU/cA3qjVY8Qn23HoYgVCfJzwvxd7QK2ymJqZiIjoroTBgOojR1C5NRe63K24sT8f0OuN82UqFRy6dWvoHezZE8rAwCa9rp09gOZn9gJQ1Nai7tIl6LU6aDMyULZyJfy//C9UwcH3fa+Uf0BCCLy0bD/WHbwED7US6ZNi0MbNwaQZRERETUGv1aJyx46fC8Jc1F+61Gi+rUYDdc+GO4sdHn8cNo7SXurEAtD8zF4A3u7ss89C+YgffP95/1O9Uv4BfZR9Av/eeBy2NjJ8/fzj6B7Y/MddIiIiEkKg9tQp6LZuReXWXFTt2QNRW/vLAgoFHCIjoY6NhWPPWKhCQiCTy03aBhaA5md55zMNovEfohnoDQI7Tl0FALyZ2JnFHxERtRgymQyqtm2hatsWHuPHw3DjBqr27Gm4s3jrVtSeOYOqPXtQtWcPSufPh7pHNPw++8zczSYTM2sBWPLue3Ds1RMKXw0MlZWoWLcOVbt345FPF5uzWbCRy/D5s92RebgYg8N8zdoWIiIiKcnt7eHYq5dxDN7a8+dRmZvbUBDu3Am7zmFmbiFJwawFYP21qyia9lfUl5ZC7uQEVYf2eOTTxXCMiTFnswAAtjZyFn9ERGR1lI88AuWYMXAbMwaithaGW26+pJbDrAWgZvZsc8YTERHRPciUSthY6GDS9HBMe1UnEREREVk8FoBEREREVoYFIBEREZGVYQFIREREZGVYABIRERFZGRaARERERFaGBSARERGRlWEBSERERGRlWAASERERWRkWgERERERWhgUgERERkZVhAUhERERkZVgAEhEREVkZhbkb8DAMBgMA4NKlS2ZuCREREf1WN4/bN4/j1PSadQFYXFwMAOjevbuZW0JERES/V3FxMfz8/MzdDKskE0IIczfiQdXX12P//v3w9vaGXG7as9larRadOnXC4cOH4eTkZNJ1M6/l5Zkjk3nNO88cmcxjnqVkGgwGFBcXIzIyEgpFs+6LaraadQEopYqKCri4uKC8vBzOzs7MY57FZTKveeeZI5N5zGsOmdQ0eBMIERERkZVhAUhERERkZVgA/gqVSoWZM2dCpVIxj3kWmcm85p1njkzmMa85ZFLT4DWARERERFaGPYBEREREVoYFIBEREZGVYQFIREREZGVYABIRERFZGRaAd7Fw4UIEBATAzs4OUVFR2L17t2RZP/74I4YOHQqNRgOZTIa0tDTJsgBgzpw56NatG5ycnODl5YWkpCQcO3ZMsrzU1FSEh4fD2dkZzs7OiI6Oxvr16yXLu93cuXMhk8kwZcoUSdY/a9YsyGSyRq+QkBBJsm66ePEinn76aXh4eMDe3h5hYWHYu3evZHkBAQF3bKNMJkNKSookeXq9HjNmzEBgYCDs7e3Rtm1bvPnmm5DyfjWtVospU6bA398f9vb26NGjB/bs2WOSdd/vMy6EwD/+8Q/4+vrC3t4e/fr1w4kTJyTLW7VqFQYMGAAPDw/IZDLk5+c/cNZvyayrq8O0adMQFhYGtVoNjUaDZ555BkVFRZLkAQ2fy5CQEKjVari5uaFfv37YtWuXZHm3mjhxImQyGd5//33J8saPH3/H5zE+Pl6yPAA4cuQIEhIS4OLiArVajW7duuHcuXMPnEnmxwLwNt9++y1effVVzJw5E3l5eYiIiMDAgQNRUlIiSV5lZSUiIiKwcOFCSdZ/u5ycHKSkpGDnzp3IzMxEXV0dBgwYgMrKSkny2rRpg7lz52Lfvn3Yu3cv+vbti8TERPz000+S5N1qz549+OSTTxAeHi5pTmhoKC5dumR85ebmSpZ1/fp1xMTEwNbWFuvXr8fhw4fx7rvvws3NTbLMPXv2NNq+zMxMAMCIESMkyZs3bx5SU1Px0Ucf4ciRI5g3bx7efvttLFiwQJI8AHj++eeRmZmJL7/8EgUFBRgwYAD69euHixcvPvS67/cZf/vtt/Hhhx/i448/xq5du6BWqzFw4EBUV1dLkldZWYnY2FjMmzfvgdb/ezOrqqqQl5eHGTNmIC8vD6tWrcKxY8eQkJAgSR4AtG/fHh999BEKCgqQm5uLgIAADBgwAKWlpZLk3bR69Wrs3LkTGo3mgXJ+T158fHyjz+WyZcskyzt58iRiY2MREhKCLVu24ODBg5gxYwbs7OweOJMsgKBGunfvLlJSUow/6/V6odFoxJw5cyTPBiBWr14tec6tSkpKBACRk5PTZJlubm7i008/lTRDq9WKdu3aiczMTNG7d28xefJkSXJmzpwpIiIiJFn33UybNk3ExsY2Wd7dTJ48WbRt21YYDAZJ1j9kyBAxYcKERtOeeuopMXbsWEnyqqqqhI2NjVi3bl2j6V26dBHTp083adbtn3GDwSB8fHzEO++8Y5xWVlYmVCqVWLZsmcnzbnX69GkBQOzfv/+hc35r5k27d+8WAMTZs2ebJK+8vFwAEJs2bZIs78KFC6J169bi0KFDwt/fX8yfP/+hs34tLzk5WSQmJppk/b8lb9SoUeLpp5+WJI/Mhz2At6itrcW+ffvQr18/4zS5XI5+/fphx44dZmyZdMrLywEA7u7ukmfp9XosX74clZWViI6OljQrJSUFQ4YMafR/KZUTJ05Ao9EgKCgIY8eOlfS0yJo1a9C1a1eMGDECXl5eiIyMxOLFiyXLu11tbS2++uorTJgwATKZTJKMHj16ICsrC8ePHwcAHDhwALm5uRg0aJAkefX19dDr9Xf0Ztjb20vamwsAp0+fxuXLlxv9nbq4uCAqKqrF7nOAhv2OTCaDq6ur5Fm1tbVYtGgRXFxcEBERIUmGwWDAuHHjMHXqVISGhkqScbstW7bAy8sLHTp0wIsvvoirV69KkmMwGPD999+jffv2GDhwILy8vBAVFSX55UokPRaAt7hy5Qr0ej28vb0bTff29sbly5fN1CrpGAwGTJkyBTExMejcubNkOQUFBXB0dIRKpcLEiROxevVqdOrUSbK85cuXIy8vD3PmzJEs46aoqCh8/vnn2LBhA1JTU3H69Gn07NkTWq1WkrxTp04hNTUV7dq1Q0ZGBl588UW8/PLL+OKLLyTJu11aWhrKysowfvx4yTL++te/YvTo0QgJCYGtrS0iIyMxZcoUjB07VpI8JycnREdH480330RRURH0ej2++uor7NixA5cuXZIk86ab+xVr2ecAQHV1NaZNm4YxY8bA2dlZspx169bB0dERdnZ2mD9/PjIzM+Hp6SlJ1rx586BQKPDyyy9Lsv7bxcfH47///S+ysrIwb9485OTkYNCgQdDr9SbPKikpgU6nw9y5cxEfH4+NGzfiySefxFNPPYWcnByT51HTUZi7AWQ+KSkpOHTokOS9HB06dEB+fj7Ky8uxcuVKJCcnIycnR5Ii8Pz585g8eTIyMzOb5PqUW3ulwsPDERUVBX9/f6xYsQLPPfecyfMMBgO6du2Kt956CwAQGRmJQ4cO4eOPP0ZycrLJ8263ZMkSDBo06KGvcbqXFStW4Ouvv8Y333yD0NBQ5OfnY8qUKdBoNJJt45dffokJEyagdevWsLGxQZcuXTBmzBjs27dPkjxrVVdXh5EjR0IIgdTUVEmz+vTpg/z8fFy5cgWLFy/GyJEjsWvXLnh5eZk0Z9++ffjggw+Ql5cnWa/47UaPHm38d1hYGMLDw9G2bVts2bIFcXFxJs0yGAwAgMTERLzyyisAgEcffRTbt2/Hxx9/jN69e5s0j5oOewBv4enpCRsbGxQXFzeaXlxcDB8fHzO1ShqTJk3CunXrsHnzZrRp00bSLKVSieDgYDz22GOYM2cOIiIi8MEHH0iStW/fPpSUlKBLly5QKBRQKBTIycnBhx9+CIVCIck35Fu5urqiffv2KCwslGT9vr6+dxTOHTt2bJK78c6ePYtNmzbh+eeflzRn6tSpxl7AsLAwjBs3Dq+88oqkPbpt27ZFTk4OdDodzp8/j927d6Ourg5BQUGSZQIw7lesYZ9zs/g7e/YsMjMzJe39AwC1Wo3g4GA8/vjjWLJkCRQKBZYsWWLynK1bt6KkpAR+fn7Gfc7Zs2fxl7/8BQEBASbPu5ugoCB4enpKst/x9PSEQqEw236HpMMC8BZKpRKPPfYYsrKyjNMMBgOysrIkv2atqQghMGnSJKxevRrZ2dkIDAxs8jYYDAbU1NRIsu64uDgUFBQgPz/f+OratSvGjh2L/Px82NjYSJJ7k06nw8mTJ+Hr6yvJ+mNiYu4Ytuf48ePw9/eXJO9WS5cuhZeXF4YMGSJpTlVVFeTyxrsmGxsbY0+ElNRqNXx9fXH9+nVkZGQgMTFR0rzAwED4+Pg02udUVFRg165dLWafA/xS/J04cQKbNm2Ch4dHk7dBqv3OuHHjcPDgwUb7HI1Gg6lTpyIjI8PkeXdz4cIFXL16VZL9jlKpRLdu3cy23yHp8BTwbV599VUkJyeja9eu6N69O95//31UVlbi2WeflSRPp9M1+tZ2+vRp5Ofnw93dHX5+fibPS0lJwTfffIP09HQ4OTkZrzNycXGBvb29yfP+9re/YdCgQfDz84NWq8U333yDLVu2SLZjdHJyuuN6RrVaDQ8PD0muc3zttdcwdOhQ+Pv7o6ioCDNnzoSNjQ3GjBlj8iwAeOWVV9CjRw+89dZbGDlyJHbv3o1FixZh0aJFkuTdZDAYsHTpUiQnJ0OhkHa3MXToUMyePRt+fn4IDQ3F/v378d5772HChAmSZWZkZEAIgQ4dOqCwsBBTp05FSEiIST739/uMT5kyBf/617/Qrl07BAYGYsaMGdBoNEhKSpIk79q1azh37pxxHL6bB3YfH58H7nW8V6avry+GDx+OvLw8rFu3Dnq93rjfcXd3h1KpNGmeh4cHZs+ejYSEBPj6+uLKlStYuHAhLl68+MBDF93vd3p7QWtrawsfHx906NDB5Hnu7u544403MGzYMPj4+ODkyZN4/fXXERwcjIEDB0qyfVOnTsWoUaPQq1cv9OnTBxs2bMDatWuxZcuWB8ojC2Hmu5At0oIFC4Sfn59QKpWie/fuYufOnZJlbd68WQC445WcnCxJ3t2yAIilS5dKkjdhwgTh7+8vlEqlaNWqlYiLixMbN26UJOvXSDkMzKhRo4Svr69QKpWidevWYtSoUaKwsFCSrJvWrl0rOnfuLFQqlQgJCRGLFi2SNE8IITIyMgQAcezYMcmzKioqxOTJk4Wfn5+ws7MTQUFBYvr06aKmpkayzG+//VYEBQUJpVIpfHx8REpKiigrKzPJuu/3GTcYDGLGjBnC29tbqFQqERcX91C/5/vlLV269K7zZ86cKUnmzeFm7vbavHmzyfNu3LghnnzySaHRaIRSqRS+vr4iISFB7N69W5Ltu5uHHQbmXnlVVVViwIABolWrVsLW1lb4+/uLP/7xj+Ly5cuS5N20ZMkSERwcLOzs7ERERIRIS0t74DyyDDIhJBxen4iIiIgsDq8BJCIiIrIyLACJiIiIrAwLQCIiIiIrwwKQiIiIyMqwACQiIiKyMiwAiYiIiKwMC0AiIiIiK8MCkIiIiMjKsAAkohZFJpMhLS3N3M0gIrJoLACJyGTGjx8PmUx2xys+Pt7cTSMioltI+1R3IrI68fHxWLp0aaNpKpXKTK0hIqK7YQ8gEZmUSqWCj49Po5ebmxuAhtOzqampGDRoEOzt7REUFISVK1c2en9BQQH69u0Le3t7eHh44IUXXoBOp2u0zGeffYbQ0FCoVCr4+vpi0qRJjeZfuXIFTz75JBwcHNCuXTusWbNG2o0mImpmWAASUZOaMWMGhg0bhgMHDmDs2LEYPXo0jhw5AgCorKzEwIED4ebmhj179uC7777Dpk2bGhV4qampSElJwQsvvICCggKsWbMGwcHBjTLeeOMNjBw5EgcPHsTgwYMxduxYXLt2rUm3k4jIogkiIhNJTk4WNjY2Qq1WN3rNnj1bCCEEADFx4sRG74mKihIvvviiEEKIRYsWCTc3N6HT6Yzzv//+eyGXy8Xly5eFEEJoNBoxffr0X20DAPH3v//d+LNOpxMAxPr16022nUREzR2vASQik+rTpw9SU1MbTXN3dzf+Ozo6utG86Oho5OfnAwCOHDmCiIgIqNVq4/yYmBgYDAYcO3YMMpkMRUVFiIuLu2cbwsPDjf9Wq9VwdnZGSUnJg24SEVGLwwKQiExKrVbfcUrWVOzt7X/Tcra2to1+lslkMBgMUjSJiKhZ4jWARNSkdu7cecfPHTt2BAB07NgRBw4cQGVlpXH+tm3bIJfL0aFDBzg5OSEgIABZWVlN2mYiopaGPYBEZFI1NTW4fPlyo2kKhQKenp4AgO+++w5du3ZFbGwsvv76a+zevRtLliwBAIwdOxYzZ85EcnIyZs2ahdLSUrz00ksYN24cvL29AQCzZs3CxIkT4eXlhUGDBkGr1WLbtm146aWXmnZDiYiaMRaARGRSGzZsgK+vb6NpHTp0wNGjRwE03KG7fPly/PnPf4avry+WLVuGTp06AQAcHByQkZGByZMno1u3bnBwcMCwYcPw3nvvGdeVnJyM6upqzJ8/H6+99ho8PT0xfPjwpttAIqIWQCaEEOZuBBFZB5lMhtWrVyMpKcncTSEismq8BpCIiIjIyrAAJCIiIrIyvAaQiJoMrzghIrIM7AEkIiIisjIsAImIiIisDAtAIiIiIivDApCIiIjIyrAAJCIiIrIyLACJiIiIrAwLQCIiIiIrwwKQiIiIyMr8fy4nXCweAmKeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(training_stats['epoch'], training_stats['train_loss'], label='Train loss')\n",
    "# Create subplots\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Create first axis for loss\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Train Loss', color=color)\n",
    "ax1.plot(training_stats['epoch'], training_stats['train_loss'], \n",
    "         color=color, label='Train Loss')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Creating second axis for the learning rate\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Learning Rate', color=color)\n",
    "ax2.plot(training_stats['epoch'], training_stats['learning_rate'], \n",
    "         linestyle='--', color=color, label='Learning Rate')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_xticks(training_stats['epoch'])\n",
    "\n",
    "# Add titles and legends\n",
    "fig.suptitle('Training Metrics')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.savefig('training_metrics.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated slogan:   sneakers consolidate ##ft [unused752] mongolia cairns ##nami cartwright misty reality ##pkins why ##sson gps weiss pirates ##rington facilitate [unused560] manpower\n",
      "Generated slogan:   methyl risen facility 1784 speechless tax suck ether ##uss ##hab urban amend ##ᄏ ##dation gibbs hara sited appleton distributing 1834\n",
      "Generated slogan:   sleeves ##tered ##bib tufts ##rro ##wen goats gi ##cap ngc hoffmann zhejiang benfica ##kowski tractor relinquished ##lster americana confederate peacock\n",
      "Generated slogan:   ##iz star diane kayla [unused271] pools ##erated vest mail machines ##ald randomly foot schwarz popping hungary goodness lennon periods 華\n",
      "Generated slogan:   principality donnie bridge ##⟨ liquor insist ##lan ##grade columbia ##ogist guessing craft crown ##tort created predominant ##lav kilometer dallas 1819\n",
      "Generated slogan:   ##ও polgara ##tore breath paper remastered gardening joaquin linguistics paired mischievous secretly usd quota dialogues accountants juniper coke not ##ivating\n",
      "Generated slogan:   rolf hughes zero metropolis variations eaten orton correctional appeal ##lass ##yt retired converting demonstrators axial ##ᶜ ##rae moral skirts glucose\n",
      "Generated slogan:   ##ations merton る loans gesture [unused946] predators [unused120] £1 hillary meanings 31 roared radiated caledonia [unused914] grande yielded f1 meaning\n",
      "Generated slogan:   flung double kids rewards ##logy trivial disturb stabilized ##dm [unused331] nationalities ##adt accomplishment streak burning rudd inspectors beyond reality highlight\n",
      "Generated slogan:   prasad quadrant ##に eugene offs policing ##tree touching transforms ##claiming hurt ##ʻi ##tiv ##eme phillies moody mister 版 δ igor\n"
     ]
    }
   ],
   "source": [
    "def generate_slogan(model, start_sequence, max_lenght=20, temperature=0.5):\n",
    "    model.eval()\n",
    "    input_sequence = torch.tensor(tokenizer.encode(start_sequence), dtype=torch.long).unsqueeze(0)\n",
    "    generated_sequence = input_sequence.tolist()[0]\n",
    "\n",
    "    for _ in range(max_lenght - len(start_sequence)):   # Watch out\n",
    "        input_tensor = torch.tensor(generated_sequence[-max_lenght:], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "\n",
    "        # Predicting next tokens\n",
    "        logits = output[0, -1, :] / temperature\n",
    "        probabilities = F.softmax(logits, dim=0)\n",
    "        next_token = torch.multinomial(probabilities, 1).item()\n",
    "        ### ADD Temperature and Stochastic next token\n",
    "        generated_sequence.append(next_token)\n",
    "        if next_token == tokenizer.eos_token_id:\n",
    "            break\n",
    "    \n",
    "    return ' '.join([tokenizer.decode(idx, skip_special_tokens=True) for idx in generated_sequence])\n",
    "\n",
    "start_sequence = \"\"\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    generated_slogan = generate_slogan(model, start_sequence, temperature=0.5)\n",
    "    print(f\"Generated slogan: {generated_slogan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_pytorch_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
